{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14175980,"sourceType":"datasetVersion","datasetId":9036289},{"sourceId":285362068,"sourceType":"kernelVersion"},{"sourceId":286089719,"sourceType":"kernelVersion"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nguynvnln22028281/btl-nlp-medical-fine-tune?scriptVersionId=286612767\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from datasets import load_dataset\nfrom datasets import DatasetDict\n\n\n# Load data\ndata_files = {\n    \"train\": \"/kaggle/input/btl-nlp-cleandata/train_cleaned.jsonl\",\n    \"test\": \"/kaggle/input/btl-nlp-cleandata/test_cleaned.jsonl\"\n}\ndataset = load_dataset(\"json\", data_files=data_files)\n\n# Create train/validation split (90/10 or 95/5)\ntrain_val_split = dataset['train'].train_test_split(\n    test_size=0.05,  # 5% for validation\n    seed=42,\n    shuffle=True  # IMPORTANT: Shuffle the data\n)\n\n# Reassemble into final dataset structure\ndataset = DatasetDict({\n    'train': train_val_split['train'],\n    'validation': train_val_split['test'],  # Note: this is validation, not test\n    'test': dataset['test']\n})\n\nprint(\"=\"*60)\nprint(\"Final dataset structure:\")\nprint(dataset)\nprint(f\"  Train: {len(dataset['train'])} pairs\")\nprint(f\"  Validation: {len(dataset['validation'])} pairs\")\nprint(f\"  Test: {len(dataset['test'])} pairs\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:27.777452Z","iopub.execute_input":"2025-12-16T12:56:27.77766Z","iopub.status.idle":"2025-12-16T12:56:36.647834Z","shell.execute_reply.started":"2025-12-16T12:56:27.777633Z","shell.execute_reply":"2025-12-16T12:56:36.647153Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f634b44df192443fafef82c83edbe65e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed18aebdace944f698fb10b99421e88a"}},"metadata":{}},{"name":"stdout","text":"============================================================\nFinal dataset structure:\nDatasetDict({\n    train: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 305942\n    })\n    validation: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 16103\n    })\n    test: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 2793\n    })\n})\n  Train: 305942 pairs\n  Validation: 16103 pairs\n  Test: 2793 pairs\n============================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def remove_train_overlaps(dataset):\n    print(\"\\n\" + \"=\"*60)\n    print(\"REMOVING TRAIN ITEMS THAT ALSO APPEAR IN TEST (HF DATASET)\")\n    print(\"=\"*60)\n\n    # Extract English sentences from test split\n    test_en = set(dataset['test']['en'])   # fast and HF compatible\n\n    old_size = len(dataset['train'])\n\n    # Use .filter() to keep only examples not in test\n    dataset['train'] = dataset['train'].filter(\n        lambda ex: ex['en'] not in test_en\n    )\n\n    new_size = len(dataset['train'])\n    removed = old_size - new_size\n\n    print(f\"Original train size: {old_size}\")\n    print(f\"New train size     : {new_size}\")\n    print(f\"Removed from train : {removed}\")\n\n    if removed > 0:\n        print(\"‚úÖ Train cleaned and test set unchanged.\")\n    else:\n        print(\"No overlaps found.\")\n\n    return dataset\ndataset = remove_train_overlaps(dataset)\n\n# Reassemble final dataset\ndataset = DatasetDict({\n    'train': dataset['train'],\n    'validation': train_val_split['test'],  # your val set\n    'test': dataset['test']\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:36.649306Z","iopub.execute_input":"2025-12-16T12:56:36.649683Z","iopub.status.idle":"2025-12-16T12:56:39.904148Z","shell.execute_reply.started":"2025-12-16T12:56:36.649665Z","shell.execute_reply":"2025-12-16T12:56:39.903351Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nREMOVING TRAIN ITEMS THAT ALSO APPEAR IN TEST (HF DATASET)\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/305942 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3508a7eeca5247f59f49ec33ff552917"}},"metadata":{}},{"name":"stdout","text":"Original train size: 305942\nNew train size     : 304286\nRemoved from train : 1656\n‚úÖ Train cleaned and test set unchanged.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast\n\ntokenizer = PreTrainedTokenizerFast.from_pretrained(\"/kaggle/input/general-envi-tokenizer\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:39.905091Z","iopub.execute_input":"2025-12-16T12:56:39.905369Z","iopub.status.idle":"2025-12-16T12:56:41.590616Z","shell.execute_reply.started":"2025-12-16T12:56:39.905344Z","shell.execute_reply":"2025-12-16T12:56:41.589807Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torch  # You also need this for torch.tensor inside __getitem__\n# ============================================================================\n# DATASET CLASS\n# ============================================================================\nclass TranslationDataset(Dataset):\n    \"\"\"Dataset for EN-VI medical translation\"\"\"\n    def __init__(self, dataset, tokenizer, max_len=512):\n        self.dataset = dataset\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.bos_id = tokenizer.bos_token_id\n        self.eos_id = tokenizer.eos_token_id\n        self.pad_id = tokenizer.pad_token_id\n    \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        \n        # Tokenize\n        src_ids = self.tokenizer.encode(item['en'], add_special_tokens=True, max_length=self.max_len, truncation=True)\n        tgt_ids = self.tokenizer.encode(item['vi'], add_special_tokens=True, max_length=self.max_len, truncation=True)\n        \n        return {\n            'src': torch.tensor(src_ids, dtype=torch.long),\n            'tgt': torch.tensor(tgt_ids, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:41.591482Z","iopub.execute_input":"2025-12-16T12:56:41.592528Z","iopub.status.idle":"2025-12-16T12:56:41.59833Z","shell.execute_reply.started":"2025-12-16T12:56:41.592505Z","shell.execute_reply":"2025-12-16T12:56:41.597599Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def collate_fn(batch, pad_id=0):\n    \"\"\"Collate function with dynamic padding\"\"\"\n    src_batch = [item['src'] for item in batch]\n    tgt_batch = [item['tgt'] for item in batch]\n    \n    # Pad sequences\n    src_padded = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=pad_id)\n    tgt_padded = nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=pad_id)\n    \n    return {\n        'src': src_padded,\n        'tgt': tgt_padded\n    }\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:41.599848Z","iopub.execute_input":"2025-12-16T12:56:41.600104Z","iopub.status.idle":"2025-12-16T12:56:41.621576Z","shell.execute_reply.started":"2025-12-16T12:56:41.600084Z","shell.execute_reply":"2025-12-16T12:56:41.620713Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset, DatasetDict\nfrom tqdm import tqdm\nimport numpy as np\n\n# ============================================================================\n# POSITIONAL ENCODING\n# ============================================================================\nclass PositionalEncoding(nn.Module):\n    \"\"\"Sinusoidal positional encoding for transformer\"\"\"\n    def __init__(self, d_model, max_len=512, dropout=0.1):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        \n        # Create positional encoding matrix\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n                            (-math.log(10000.0) / d_model))\n        \n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n        \n        self.register_buffer('pe', pe)\n    \n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: (batch_size, seq_len, d_model)\n        \"\"\"\n        x = x + self.pe[:, :x.size(1), :]\n        return self.dropout(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:41.623738Z","iopub.execute_input":"2025-12-16T12:56:41.624229Z","iopub.status.idle":"2025-12-16T12:56:41.636576Z","shell.execute_reply.started":"2025-12-16T12:56:41.624211Z","shell.execute_reply":"2025-12-16T12:56:41.635992Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ============================================================================\n# MULTI-HEAD ATTENTION\n# ============================================================================\nclass MultiHeadAttention(nn.Module):\n    \"\"\"Multi-head self-attention mechanism\"\"\"\n    def __init__(self, d_model, num_heads, dropout=0.1):\n        super().__init__()\n        assert d_model % num_heads == 0\n        \n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n        \n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n        self.W_o = nn.Linear(d_model, d_model)\n        \n        self.dropout = nn.Dropout(dropout)\n    \n    def split_heads(self, x):\n        \"\"\"Split into multiple heads: (batch, seq_len, d_model) -> (batch, num_heads, seq_len, d_k)\"\"\"\n        batch_size, seq_len, d_model = x.size()\n        return x.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n    \n    def combine_heads(self, x):\n        \"\"\"Combine heads: (batch, num_heads, seq_len, d_k) -> (batch, seq_len, d_model)\"\"\"\n        batch_size, num_heads, seq_len, d_k = x.size()\n        return x.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n    \n    def forward(self, query, key, value, mask=None):\n        \"\"\"\n        Args:\n            query, key, value: (batch_size, seq_len, d_model)\n            mask: (batch_size, 1, seq_len, seq_len) or (batch_size, 1, 1, seq_len)\n        \"\"\"\n        batch_size = query.size(0)\n        \n        # Linear projections and split heads\n        Q = self.split_heads(self.W_q(query))  # (batch, num_heads, seq_len, d_k)\n        K = self.split_heads(self.W_k(key))\n        V = self.split_heads(self.W_v(value))\n        \n        # Scaled dot-product attention\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n        \n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n        \n        attn_weights = F.softmax(scores, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n        \n        attn_output = torch.matmul(attn_weights, V)  # (batch, num_heads, seq_len, d_k)\n        \n        # Combine heads and final linear\n        attn_output = self.combine_heads(attn_output)  # (batch, seq_len, d_model)\n        output = self.W_o(attn_output)\n        \n        return output\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:41.637311Z","iopub.execute_input":"2025-12-16T12:56:41.637626Z","iopub.status.idle":"2025-12-16T12:56:41.653511Z","shell.execute_reply.started":"2025-12-16T12:56:41.637602Z","shell.execute_reply":"2025-12-16T12:56:41.652845Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ============================================================================\n# FEED FORWARD NETWORK\n# ============================================================================\nclass FeedForward(nn.Module):\n    \"\"\"Position-wise feed-forward network\"\"\"\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super().__init__()\n        self.linear1 = nn.Linear(d_model, d_ff)\n        self.linear2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, x):\n        return self.linear2(self.dropout(F.relu(self.linear1(x))))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:41.654278Z","iopub.execute_input":"2025-12-16T12:56:41.65447Z","iopub.status.idle":"2025-12-16T12:56:41.668976Z","shell.execute_reply.started":"2025-12-16T12:56:41.654454Z","shell.execute_reply":"2025-12-16T12:56:41.668376Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ============================================================================\n# ENCODER LAYER\n# ============================================================================\nclass EncoderLayer(nn.Module):\n    \"\"\"Single encoder layer with self-attention and feed-forward\"\"\"\n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        super().__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n        \n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n    \n    def forward(self, x, mask):\n        # Self-attention with residual connection\n        attn_output = self.self_attn(x, x, x, mask)\n        x = self.norm1(x + self.dropout1(attn_output))\n        \n        # Feed-forward with residual connection\n        ff_output = self.feed_forward(x)\n        x = self.norm2(x + self.dropout2(ff_output))\n        \n        return x\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:41.669578Z","iopub.execute_input":"2025-12-16T12:56:41.669819Z","iopub.status.idle":"2025-12-16T12:56:41.684395Z","shell.execute_reply.started":"2025-12-16T12:56:41.669798Z","shell.execute_reply":"2025-12-16T12:56:41.683847Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# ============================================================================\n# DECODER LAYER\n# ============================================================================\nclass DecoderLayer(nn.Module):\n    \"\"\"Single decoder layer with self-attention, cross-attention, and feed-forward\"\"\"\n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        super().__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)\n        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n        \n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        \n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n        self.dropout3 = nn.Dropout(dropout)\n    \n    def forward(self, x, encoder_output, src_mask, tgt_mask):\n        # Self-attention on target\n        attn_output = self.self_attn(x, x, x, tgt_mask)\n        x = self.norm1(x + self.dropout1(attn_output))\n        \n        # Cross-attention on encoder output\n        cross_attn_output = self.cross_attn(x, encoder_output, encoder_output, src_mask)\n        x = self.norm2(x + self.dropout2(cross_attn_output))\n        \n        # Feed-forward\n        ff_output = self.feed_forward(x)\n        x = self.norm3(x + self.dropout3(ff_output))\n        \n        return x\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:41.685146Z","iopub.execute_input":"2025-12-16T12:56:41.685419Z","iopub.status.idle":"2025-12-16T12:56:41.698077Z","shell.execute_reply.started":"2025-12-16T12:56:41.685404Z","shell.execute_reply":"2025-12-16T12:56:41.697385Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ============================================================================\n# TRANSFORMER MODEL\n# ============================================================================\nclass TransformerTranslator(nn.Module):\n    \"\"\"Complete Transformer model for EN-VI medical translation\"\"\"\n    def __init__(\n        self,\n        vocab_size,\n        d_model=512,\n        num_heads=8,\n        num_encoder_layers=6,\n        num_decoder_layers=6,\n        d_ff=2048,\n        max_len=512,\n        dropout=0.1,\n        pad_idx=0\n    ):\n        super().__init__()\n        \n        self.d_model = d_model\n        self.pad_idx = pad_idx\n        \n        # Embeddings\n        self.encoder_embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n        self.decoder_embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n        \n        # Positional encoding\n        self.pos_encoding = PositionalEncoding(d_model, max_len, dropout)\n        \n        # Encoder and Decoder stacks\n        self.encoder_layers = nn.ModuleList([\n            EncoderLayer(d_model, num_heads, d_ff, dropout)\n            for _ in range(num_encoder_layers)\n        ])\n        \n        self.decoder_layers = nn.ModuleList([\n            DecoderLayer(d_model, num_heads, d_ff, dropout)\n            for _ in range(num_decoder_layers)\n        ])\n        \n        # Output projection\n        self.output_projection = nn.Linear(d_model, vocab_size)\n        \n        # Initialize weights\n        self._init_weights()\n    \n    def _init_weights(self):\n        \"\"\"Initialize weights using Xavier uniform\"\"\"\n        for p in self.parameters():\n            if p.dim() > 1:\n                nn.init.xavier_uniform_(p)\n    \n    def make_src_mask(self, src):\n        \"\"\"Create padding mask for source: (batch, 1, 1, src_len)\"\"\"\n        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)\n        return src_mask\n    \n    def make_tgt_mask(self, tgt):\n        \"\"\"Create causal mask for target: (batch, 1, tgt_len, tgt_len)\"\"\"\n        batch_size, tgt_len = tgt.size()\n        \n        # Padding mask\n        tgt_pad_mask = (tgt != self.pad_idx).unsqueeze(1).unsqueeze(2)  # (batch, 1, 1, tgt_len)\n        \n        # Causal mask (lower triangular)\n        tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()\n        tgt_sub_mask = tgt_sub_mask.unsqueeze(0).unsqueeze(0)  # (1, 1, tgt_len, tgt_len)\n        \n        tgt_mask = tgt_pad_mask & tgt_sub_mask\n        return tgt_mask\n    \n    def encode(self, src, src_mask):\n        \"\"\"Encode source sequence\"\"\"\n        # Embedding + positional encoding\n        x = self.encoder_embedding(src) * math.sqrt(self.d_model)\n        x = self.pos_encoding(x)\n        \n        # Pass through encoder layers\n        for layer in self.encoder_layers:\n            x = layer(x, src_mask)\n        \n        return x\n    \n    def decode(self, tgt, encoder_output, src_mask, tgt_mask):\n        \"\"\"Decode target sequence\"\"\"\n        # Embedding + positional encoding\n        x = self.decoder_embedding(tgt) * math.sqrt(self.d_model)\n        x = self.pos_encoding(x)\n        \n        # Pass through decoder layers\n        for layer in self.decoder_layers:\n            x = layer(x, encoder_output, src_mask, tgt_mask)\n        \n        return x\n    \n    def forward(self, src, tgt):\n        \"\"\"\n        Args:\n            src: (batch_size, src_len)\n            tgt: (batch_size, tgt_len)\n        Returns:\n            output: (batch_size, tgt_len, vocab_size)\n        \"\"\"\n        src_mask = self.make_src_mask(src)\n        tgt_mask = self.make_tgt_mask(tgt)\n        \n        encoder_output = self.encode(src, src_mask)\n        decoder_output = self.decode(tgt, encoder_output, src_mask, tgt_mask)\n        \n        output = self.output_projection(decoder_output)\n        return output\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:41.699427Z","iopub.execute_input":"2025-12-16T12:56:41.699687Z","iopub.status.idle":"2025-12-16T12:56:41.716685Z","shell.execute_reply.started":"2025-12-16T12:56:41.699667Z","shell.execute_reply":"2025-12-16T12:56:41.715979Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ============================================================================\n# TRAINING FUNCTION\n# ============================================================================\ndef train_epoch(model, dataloader, optimizer, criterion, device, grad_clip=1.0):\n    \"\"\"Train for one epoch\"\"\"\n    model.train()\n    total_loss = 0\n    \n    pbar = tqdm(dataloader, desc=\"Training\")\n    for batch in pbar:\n        src = batch['src'].to(device)\n        tgt = batch['tgt'].to(device)\n        \n        # Teacher forcing: use tgt[:-1] as input, predict tgt[1:]\n        tgt_input = tgt[:, :-1]\n        tgt_output = tgt[:, 1:]\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        output = model(src, tgt_input)  # (batch, tgt_len-1, vocab_size)\n        \n        # Compute loss\n        output = output.reshape(-1, output.size(-1))\n        tgt_output = tgt_output.reshape(-1)\n        loss = criterion(output, tgt_output)\n        \n        # Backward pass\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n        optimizer.step()\n        \n        total_loss += loss.item()\n        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n    \n    return total_loss / len(dataloader)\n\ndef evaluate(model, dataloader, criterion, device):\n    \"\"\"Evaluate the model\"\"\"\n    model.eval()\n    total_loss = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            src = batch['src'].to(device)\n            tgt = batch['tgt'].to(device)\n            \n            tgt_input = tgt[:, :-1]\n            tgt_output = tgt[:, 1:]\n            \n            output = model(src, tgt_input)\n            \n            output = output.reshape(-1, output.size(-1))\n            tgt_output = tgt_output.reshape(-1)\n            loss = criterion(output, tgt_output)\n            \n            total_loss += loss.item()\n    \n    return total_loss / len(dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:41.717443Z","iopub.execute_input":"2025-12-16T12:56:41.718168Z","iopub.status.idle":"2025-12-16T12:56:41.735628Z","shell.execute_reply.started":"2025-12-16T12:56:41.718141Z","shell.execute_reply":"2025-12-16T12:56:41.73494Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:41.736345Z","iopub.execute_input":"2025-12-16T12:56:41.736667Z","iopub.status.idle":"2025-12-16T12:56:46.17471Z","shell.execute_reply.started":"2025-12-16T12:56:41.736595Z","shell.execute_reply":"2025-12-16T12:56:46.173979Z"}},"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2025.11.3)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.2.0 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def translate_sentence(model, tokenizer, sentence, device, max_len=100):\n    model.eval()\n\n    # Tokenize input\n    encoded = tokenizer(\n        sentence,\n        return_tensors=\"pt\",\n        padding=False,\n        truncation=True\n    )\n    src = encoded[\"input_ids\"].to(device)\n\n    # Decode using greedy search\n    pred_ids = greedy_decode(model, src, tokenizer, max_len=max_len)[0].tolist()\n\n    # Trim at EOS\n    if tokenizer.eos_token_id in pred_ids:\n        pred_ids = pred_ids[:pred_ids.index(tokenizer.eos_token_id)]\n\n    # Convert to text\n    translation = tokenizer.decode(pred_ids, skip_special_tokens=True)\n    return translation\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:46.175836Z","iopub.execute_input":"2025-12-16T12:56:46.176128Z","iopub.status.idle":"2025-12-16T12:56:46.181824Z","shell.execute_reply.started":"2025-12-16T12:56:46.176093Z","shell.execute_reply":"2025-12-16T12:56:46.181081Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import random\n\ndef get_random_test_examples(dataset, n=5):\n    indices = random.sample(range(len(dataset['test'])), n)\n    return [dataset['test'][i]['en'] for i in indices]\n\n# Example: Sample 5 random English sentences\nmedical_examples = get_random_test_examples(dataset, n=5)\n\nprint(medical_examples)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:46.182607Z","iopub.execute_input":"2025-12-16T12:56:46.182868Z","iopub.status.idle":"2025-12-16T12:56:46.201804Z","shell.execute_reply.started":"2025-12-16T12:56:46.182852Z","shell.execute_reply":"2025-12-16T12:56:46.20106Z"}},"outputs":[{"name":"stdout","text":"['A cross-sectional descriptive study was performed to assess the hearing status of armored tank soldiers.', 'Pherochromocytomas is a rare disease in children with the estimated incidence is about 1 per 50.000 to 100.000 children.', 'The most common lesions are: frosted glass (91.5%), solidified (22.6%), interstitial thickening (14.2%).', 'Health related quality of life score and standard deviation of all 324 study subjects were 0.874 ¬± 0.216, respectively.', 'Surgical outcomes of cerebellopontine angle tumors']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import sacrebleu\n\n# ============================================================================\n# Greedy Decode\n# ============================================================================\ndef greedy_decode(model, src, tokenizer, max_len=100):\n    model.eval()\n    device = src.device\n\n    sos_id = tokenizer.bos_token_id\n    eos_id = tokenizer.eos_token_id\n    pad_id = tokenizer.pad_token_id\n\n    # Create source mask\n    src_mask = model.make_src_mask(src)\n\n    with torch.no_grad():\n\n        # Encode source sequence\n        memory = model.encode(src, src_mask)\n\n        # Start decoder input with <sos>\n        ys = torch.full(\n            (src.size(0), 1),\n            fill_value=sos_id,\n            dtype=torch.long,\n            device=device\n        )\n\n        for _ in range(max_len):\n\n            # Create target/causal mask\n            tgt_mask = model.make_tgt_mask(ys)\n\n            # Decode\n            out = model.decode(ys, memory, src_mask, tgt_mask)\n\n            # Project to vocab & pick top token\n            logits = model.output_projection(out[:, -1])  # last step\n            next_word = torch.argmax(logits, dim=-1).unsqueeze(1)\n\n            # Append\n            ys = torch.cat([ys, next_word], dim=1)\n\n            # Stop if all sentences predicted EOS\n            if (next_word == eos_id).all():\n                break\n\n    return ys\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:46.202587Z","iopub.execute_input":"2025-12-16T12:56:46.202991Z","iopub.status.idle":"2025-12-16T12:56:46.284996Z","shell.execute_reply.started":"2025-12-16T12:56:46.202975Z","shell.execute_reply":"2025-12-16T12:56:46.284488Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# ============================================================================\n# Proper BLEU Computation (Correct sacrebleu Format)\n# ============================================================================\n\ndef compute_bleu(model, dataloader, tokenizer, device):\n    model.eval()\n\n    hypotheses = []\n    reference_stream = []\n\n    for batch in dataloader:\n\n        # match collate_fn keys\n        src = batch[\"src\"].to(device)\n        tgt = batch[\"tgt\"]\n\n        # Greedy decode predictions\n        pred_ids = greedy_decode(model, src, tokenizer, max_len=100)\n\n        for i in range(src.size(0)):\n\n            # ----- Decode Prediction -----\n            pred = pred_ids[i].tolist()\n            if tokenizer.eos_token_id in pred:\n                pred = pred[:pred.index(tokenizer.eos_token_id)]\n            pred_text = tokenizer.decode(pred, skip_special_tokens=True)\n\n            # ----- Decode Reference -----\n            ref = tgt[i].tolist()\n            if tokenizer.eos_token_id in ref:\n                ref = ref[:ref.index(tokenizer.eos_token_id)]\n            ref_text = tokenizer.decode(ref, skip_special_tokens=True)\n\n            hypotheses.append(pred_text)\n            reference_stream.append(ref_text)\n\n    bleu = sacrebleu.corpus_bleu(hypotheses, [reference_stream])\n    return bleu.score\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:46.285759Z","iopub.execute_input":"2025-12-16T12:56:46.286483Z","iopub.status.idle":"2025-12-16T12:56:46.292088Z","shell.execute_reply.started":"2025-12-16T12:56:46.286456Z","shell.execute_reply":"2025-12-16T12:56:46.291478Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"\nimport torch.optim as optim\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import LambdaLR\n\n# Fine-tuning Hyperparameters (ADJUSTED FOR 9.4 POINT GAP)\nBATCH_SIZE = 32\nNUM_EPOCHS = 4              # More epochs due to significant gap\nLEARNING_RATE = 5e-5        # Standard fine-tuning LR\nWEIGHT_DECAY = 0.01\nWARMUP_RATIO = 0.1\nMAX_GRAD_NORM = 1.0\n\n# Model architecture (unchanged)\nD_MODEL = 256\nNUM_HEADS = 8\nNUM_LAYERS = 4\nD_FF = 1024\nDROPOUT = 0.15\nMAX_LEN = 128\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Datasets\ntrain_dataset = TranslationDataset(dataset[\"train\"], tokenizer, max_len=MAX_LEN)\nval_dataset = TranslationDataset(dataset[\"validation\"], tokenizer, max_len=MAX_LEN)\ntest_dataset = TranslationDataset(dataset[\"test\"], tokenizer, max_len=MAX_LEN)\n\n# Dataloaders\ntrain_loader = DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n    collate_fn=lambda b: collate_fn(b, tokenizer.pad_token_id),\n    num_workers=2\n)\nval_loader = DataLoader(\n    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n    collate_fn=lambda b: collate_fn(b, tokenizer.pad_token_id),\n    num_workers=2\n)\ntest_loader = DataLoader(\n    test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n    collate_fn=lambda b: collate_fn(b, tokenizer.pad_token_id),\n    num_workers=2\n)\n\n# Model\nmodel = TransformerTranslator(\n    vocab_size=tokenizer.vocab_size,\n    d_model=D_MODEL, num_heads=NUM_HEADS,\n    num_encoder_layers=NUM_LAYERS,\n    num_decoder_layers=NUM_LAYERS,\n    d_ff=D_FF, max_len=MAX_LEN,\n    dropout=DROPOUT,\n    pad_idx=tokenizer.pad_token_id\n).to(device)\n\n# Load pre-trained checkpoint\ncheckpoint = torch.load(\n    \"/kaggle/input/btl-nlp-1-general/best_medical_translator.pt\",\n    map_location=device\n)\n\nif isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n    model.load_state_dict(checkpoint['model_state_dict'])\n    print(f\"‚úì Loaded pre-trained checkpoint\")\n    print(f\"  General training val loss: {checkpoint.get('val_loss', 'N/A')}\")\nelse:\n    model.load_state_dict(checkpoint)\n\nmodel.to(device)\nprint(f\"Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n# Loss with label smoothing\ncriterion = nn.CrossEntropyLoss(\n    ignore_index=tokenizer.pad_token_id,\n    label_smoothing=0.1\n)\n\n# Optimizer\noptimizer = AdamW(\n    model.parameters(),\n    lr=LEARNING_RATE,\n    betas=(0.9, 0.999),\n    eps=1e-9,\n    weight_decay=WEIGHT_DECAY\n)\n\n# Scheduler with warmup\nnum_training_samples = len(train_dataset)\nsteps_per_epoch = num_training_samples // BATCH_SIZE\ntotal_steps = steps_per_epoch * NUM_EPOCHS\nwarmup_steps = int(total_steps * WARMUP_RATIO)\n\nprint(f\"\\n{'='*60}\")\nprint(\"TRAINING CONFIGURATION\")\nprint(f\"{'='*60}\")\nprint(f\"Training samples:  {num_training_samples:,}\")\nprint(f\"Steps per epoch:   {steps_per_epoch:,}\")\nprint(f\"Total steps:       {total_steps:,}\")\nprint(f\"Warmup steps:      {warmup_steps:,}\")\nprint(f\"Learning rate:     {LEARNING_RATE:.0e}\")\nprint(f\"Batch size:        {BATCH_SIZE}\")\nprint(f\"Epochs:            {NUM_EPOCHS}\")\nprint(f\"{'='*60}\\n\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:56:46.294581Z","iopub.execute_input":"2025-12-16T12:56:46.294944Z","iopub.status.idle":"2025-12-16T12:56:52.797026Z","shell.execute_reply.started":"2025-12-16T12:56:46.294928Z","shell.execute_reply":"2025-12-16T12:56:52.796343Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n‚úì Loaded pre-trained checkpoint\n  General training val loss: 1.7248256816420444\nModel Parameters: 38,132,800\n\n============================================================\nTRAINING CONFIGURATION\n============================================================\nTraining samples:  304,286\nSteps per epoch:   9,508\nTotal steps:       38,032\nWarmup steps:      3,803\nLearning rate:     5e-05\nBatch size:        32\nEpochs:            4\n============================================================\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def lr_lambda(current_step):\n    if current_step < warmup_steps:\n        return float(current_step) / float(max(1, warmup_steps))\n    return max(0.0, float(total_steps - current_step) / float(max(1, total_steps - warmup_steps)))\n\nscheduler = LambdaLR(optimizer, lr_lambda)\n\n# Baseline: Test pre-trained model on medical data\nprint(\"=\"*60)\nprint(\"BASELINE: TESTING PRE-TRAINED MODEL ON MEDICAL DATA\")\nprint(\"=\"*60)\nbaseline_bleu = compute_bleu(model, test_loader, tokenizer, device)\nprint(f\"Pre-trained Medical BLEU: {baseline_bleu:.2f}\")\nprint(f\"Target after fine-tuning: {baseline_bleu + 8:.2f} - {baseline_bleu + 12:.2f}\")\nprint(f\"{'='*60}\\n\")\n\n# Training loop\nbest_val_loss = float(\"inf\")\nbest_medical_bleu = baseline_bleu  # Start from baseline\npatience_counter = 0\npatience = 3  # Increased patience since we expect continuous improvement\nglobal_step = 0\n\nfor epoch in range(NUM_EPOCHS):\n    print(\"\\n\" + \"=\"*60)\n    print(f\"EPOCH {epoch + 1}/{NUM_EPOCHS}\")\n    print(\"=\"*60)\n    \n    # Training\n    model.train()\n    total_loss = 0\n    \n    for batch_idx, batch in enumerate(train_loader):\n        src = batch[\"src\"].to(device)\n        tgt = batch[\"tgt\"].to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        output = model(src, tgt[:, :-1])\n        \n        # Calculate loss\n        output = output.contiguous().view(-1, output.size(-1))\n        tgt_out = tgt[:, 1:].contiguous().view(-1)\n        loss = criterion(output, tgt_out)\n        \n        # Backward pass\n        loss.backward()\n        \n        # Gradient clipping\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=MAX_GRAD_NORM)\n        \n        optimizer.step()\n        scheduler.step()\n        \n        total_loss += loss.item()\n        global_step += 1\n        \n        # Log progress every 500 steps\n        if (batch_idx + 1) % 500 == 0:\n            current_lr = scheduler.get_last_lr()[0]\n            avg_loss = total_loss / (batch_idx + 1)\n            print(f\"  Step {global_step:,}/{total_steps:,} | \"\n                  f\"Loss: {loss.item():.4f} | \"\n                  f\"Avg: {avg_loss:.4f} | \"\n                  f\"LR: {current_lr:.2e}\")\n    \n    train_loss = total_loss / len(train_loader)\n    \n    # Validation\n    val_loss = evaluate(model, val_loader, criterion, device)\n    current_lr = scheduler.get_last_lr()[0]\n    \n    # Calculate BLEU on medical test set\n    print(\"\\nEvaluating BLEU score...\")\n    bleu_medical = compute_bleu(model, test_loader, tokenizer, device)\n    \n    # Monitor performance\n    print(f\"\\n{'='*60}\")\n    print(f\"EPOCH {epoch + 1} RESULTS\")\n    print(f\"{'='*60}\")\n    print(f\"Train Loss:     {train_loss:.4f}\")\n    print(f\"Val Loss:       {val_loss:.4f}\")\n    print(f\"Medical BLEU:   {bleu_medical:.2f}\")\n    print(f\"Improvement:    {bleu_medical - baseline_bleu:+.2f} points from baseline\")\n    print(f\"Learning Rate:  {current_lr:.2e}\")\n    \n    # Progress indicator\n    target_bleu = 38  # Match general performance\n    progress = min(100, ((bleu_medical - baseline_bleu) / (target_bleu - baseline_bleu)) * 100)\n    if progress > 0:\n        print(f\"Progress:       {progress:.1f}% toward target BLEU {target_bleu}\")\n    \n    if bleu_medical < 32:\n        print(\"Status:         ‚ö†Ô∏è  Needs more training\")\n    elif bleu_medical < 36:\n        print(\"Status:         üìà Good progress\")\n    elif bleu_medical < 38:\n        print(\"Status:         ‚úì  Near target\")\n    else:\n        print(\"Status:         üéâ Excellent!\")\n    print(f\"{'='*60}\\n\")\n    \n    # Sample translations\n    print(\"Sample Medical Translations:\")\n    for i, s in enumerate(medical_examples[:3], 1):\n        translation = translate_sentence(model, tokenizer, s, device)\n        print(f\"{i}. EN: {s}\")\n        print(f\"   VI: {translation}\\n\")\n    \n    # Save best model based on BLEU\n    if bleu_medical > best_medical_bleu:\n        improvement = bleu_medical - best_medical_bleu\n        best_medical_bleu = bleu_medical\n        patience_counter = 0\n        \n        torch.save({\n            \"epoch\": epoch + 1,\n            \"model_state_dict\": model.state_dict(),\n            \"optimizer_state_dict\": optimizer.state_dict(),\n            \"val_loss\": val_loss,\n            \"train_loss\": train_loss,\n            \"medical_bleu\": bleu_medical,\n            \"baseline_bleu\": baseline_bleu,\n            \"improvement\": bleu_medical - baseline_bleu,\n        }, \"best_medical_finetuned.pt\")\n        \n        print(f\"‚úì Saved best model (BLEU: {bleu_medical:.2f}, +{improvement:.2f})\")\n    else:\n        patience_counter += 1\n        print(f\"No BLEU improvement (patience: {patience_counter}/{patience})\")\n        \n        if patience_counter >= patience:\n            print(f\"\\n‚ö†Ô∏è  Early stopping at epoch {epoch + 1}\")\n            print(f\"Best Medical BLEU: {best_medical_bleu:.2f}\")\n            break\n\n# Final evaluation\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINE-TUNING COMPLETE!\")\nprint(\"=\"*60)\n\n# Load best model\ncheckpoint = torch.load(\"best_medical_finetuned.pt\")\nmodel.load_state_dict(checkpoint['model_state_dict'])\n\nprint(f\"\\nBest model from epoch {checkpoint['epoch']}\")\nprint(f\"  Medical BLEU:      {checkpoint['medical_bleu']:.2f}\")\nprint(f\"  Baseline BLEU:     {checkpoint['baseline_bleu']:.2f}\")\nprint(f\"  Total improvement: {checkpoint['improvement']:+.2f} points\")\nprint(f\"  Val Loss:          {checkpoint['val_loss']:.4f}\")\n\n# Final test set evaluation\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINAL EVALUATION\")\nprint(\"=\"*60)\nfinal_bleu = compute_bleu(model, test_loader, tokenizer, device)\nprint(f\"Final Medical BLEU:    {final_bleu:.2f}\")\nprint(f\"Pre-trained BLEU:      {baseline_bleu:.2f}\")\nprint(f\"Improvement:           {final_bleu - baseline_bleu:+.2f} points\")\nprint(f\"General BLEU target:   38.0\")\n\nif final_bleu >= 38:\n    print(f\"\\nüéâ SUCCESS! Matched/exceeded general performance!\")\nelif final_bleu >= 35:\n    print(f\"\\n‚úì Good result! Close to general performance\")\nelif final_bleu >= 32:\n    print(f\"\\nüìà Solid improvement, but room to grow\")\n\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:57:59.484416Z","iopub.execute_input":"2025-12-16T12:57:59.485038Z","iopub.status.idle":"2025-12-16T14:09:44.798429Z","shell.execute_reply.started":"2025-12-16T12:57:59.485013Z","shell.execute_reply":"2025-12-16T14:09:44.797457Z"}},"outputs":[{"name":"stdout","text":"============================================================\nBASELINE: TESTING PRE-TRAINED MODEL ON MEDICAL DATA\n============================================================\nPre-trained Medical BLEU: 28.60\nTarget after fine-tuning: 36.60 - 40.60\n============================================================\n\n\n============================================================\nEPOCH 1/4\n============================================================\n  Step 500/38,032 | Loss: 4.5298 | Avg: 4.9805 | LR: 6.57e-06\n  Step 1,000/38,032 | Loss: 4.4007 | Avg: 4.7309 | LR: 1.31e-05\n  Step 1,500/38,032 | Loss: 4.0215 | Avg: 4.5045 | LR: 1.97e-05\n  Step 2,000/38,032 | Loss: 3.6439 | Avg: 4.3464 | LR: 2.63e-05\n  Step 2,500/38,032 | Loss: 4.0119 | Avg: 4.2235 | LR: 3.29e-05\n  Step 3,000/38,032 | Loss: 3.2410 | Avg: 4.1200 | LR: 3.94e-05\n  Step 3,500/38,032 | Loss: 3.6721 | Avg: 4.0337 | LR: 4.60e-05\n  Step 4,000/38,032 | Loss: 3.3030 | Avg: 3.9587 | LR: 4.97e-05\n  Step 4,500/38,032 | Loss: 3.3949 | Avg: 3.8945 | LR: 4.90e-05\n  Step 5,000/38,032 | Loss: 3.0688 | Avg: 3.8388 | LR: 4.83e-05\n  Step 5,500/38,032 | Loss: 3.1878 | Avg: 3.7884 | LR: 4.75e-05\n  Step 6,000/38,032 | Loss: 3.0958 | Avg: 3.7447 | LR: 4.68e-05\n  Step 6,500/38,032 | Loss: 3.1641 | Avg: 3.7049 | LR: 4.61e-05\n  Step 7,000/38,032 | Loss: 3.1738 | Avg: 3.6687 | LR: 4.53e-05\n  Step 7,500/38,032 | Loss: 3.1530 | Avg: 3.6369 | LR: 4.46e-05\n  Step 8,000/38,032 | Loss: 3.3274 | Avg: 3.6072 | LR: 4.39e-05\n  Step 8,500/38,032 | Loss: 3.2447 | Avg: 3.5798 | LR: 4.31e-05\n  Step 9,000/38,032 | Loss: 3.1842 | Avg: 3.5542 | LR: 4.24e-05\n  Step 9,500/38,032 | Loss: 3.1353 | Avg: 3.5308 | LR: 4.17e-05\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 504/504 [00:17<00:00, 29.15it/s]","output_type":"stream"},{"name":"stdout","text":"\nEvaluating BLEU score...\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEPOCH 1 RESULTS\n============================================================\nTrain Loss:     3.5304\nVal Loss:       2.9319\nMedical BLEU:   40.51\nImprovement:    +11.92 points from baseline\nLearning Rate:  4.17e-05\nProgress:       100.0% toward target BLEU 38\nStatus:         üéâ Excellent!\n============================================================\n\nSample Medical Translations:\n1. EN: A cross-sectional descriptive study was performed to assess the hearing status of armored tank soldiers.\n   VI: nghi√™n c·ª©u m√¥ t·∫£ c·∫Øt ngang ƒë∆∞·ª£c th·ª±c hi·ªán nh·∫±m ƒë√°nh gi√° t√¨nh tr·∫°ng nghe c·ªßa c√°c binh sƒ© xe b·ªçc th√©p.\n\n2. EN: Pherochromocytomas is a rare disease in children with the estimated incidence is about 1 per 50.000 to 100.000 children.\n   VI: pherochromocytomas l√† m·ªôt b·ªánh hi·∫øm g·∫∑p ·ªü tr·∫ª em c√≥ t·ª∑ l·ªá ∆∞·ªõc t√≠nh kho·∫£ng 1 tr√™n 50,000 ƒë·∫øn 100,000 tr·∫ª em.\n\n3. EN: The most common lesions are: frosted glass (91.5%), solidified (22.6%), interstitial thickening (14.2%).\n   VI: c√°c t·ªïn th∆∞∆°ng ph·ªï bi·∫øn nh·∫•t l√†: h·ªôi ch·ª©ng gi·∫£m gi√° (91,5%), ƒë·∫∑c hi·ªáu (22,6%), d√†y k·∫Ω (14,2%).\n\n‚úì Saved best model (BLEU: 40.51, +11.92)\n\n============================================================\nEPOCH 2/4\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  Step 10,009/38,032 | Loss: 2.9372 | Avg: 3.0690 | LR: 4.09e-05\n  Step 10,509/38,032 | Loss: 3.1597 | Avg: 3.0713 | LR: 4.02e-05\n  Step 11,009/38,032 | Loss: 3.0062 | Avg: 3.0643 | LR: 3.95e-05\n  Step 11,509/38,032 | Loss: 3.0953 | Avg: 3.0605 | LR: 3.87e-05\n  Step 12,009/38,032 | Loss: 3.1527 | Avg: 3.0553 | LR: 3.80e-05\n  Step 12,509/38,032 | Loss: 2.9949 | Avg: 3.0510 | LR: 3.73e-05\n  Step 13,009/38,032 | Loss: 2.9143 | Avg: 3.0474 | LR: 3.66e-05\n  Step 13,509/38,032 | Loss: 2.8249 | Avg: 3.0440 | LR: 3.58e-05\n  Step 14,009/38,032 | Loss: 3.2429 | Avg: 3.0409 | LR: 3.51e-05\n  Step 14,509/38,032 | Loss: 2.8653 | Avg: 3.0377 | LR: 3.44e-05\n  Step 15,009/38,032 | Loss: 3.0110 | Avg: 3.0354 | LR: 3.36e-05\n  Step 15,509/38,032 | Loss: 2.8685 | Avg: 3.0311 | LR: 3.29e-05\n  Step 16,009/38,032 | Loss: 2.8930 | Avg: 3.0281 | LR: 3.22e-05\n  Step 16,509/38,032 | Loss: 3.0310 | Avg: 3.0244 | LR: 3.14e-05\n  Step 17,009/38,032 | Loss: 3.0538 | Avg: 3.0202 | LR: 3.07e-05\n  Step 17,509/38,032 | Loss: 3.2058 | Avg: 3.0170 | LR: 3.00e-05\n  Step 18,009/38,032 | Loss: 2.8014 | Avg: 3.0136 | LR: 2.92e-05\n  Step 18,509/38,032 | Loss: 3.0016 | Avg: 3.0107 | LR: 2.85e-05\n  Step 19,009/38,032 | Loss: 2.7851 | Avg: 3.0081 | LR: 2.78e-05\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEvaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 504/504 [00:17<00:00, 29.42it/s]","output_type":"stream"},{"name":"stdout","text":"\nEvaluating BLEU score...\n","output_type":"stream"},{"name":"stderr","text":"\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEPOCH 2 RESULTS\n============================================================\nTrain Loss:     3.0080\nVal Loss:       2.8105\nMedical BLEU:   42.48\nImprovement:    +13.89 points from baseline\nLearning Rate:  2.78e-05\nProgress:       100.0% toward target BLEU 38\nStatus:         üéâ Excellent!\n============================================================\n\nSample Medical Translations:\n1. EN: A cross-sectional descriptive study was performed to assess the hearing status of armored tank soldiers.\n   VI: nghi√™n c·ª©u m√¥ t·∫£ c·∫Øt ngang ƒë∆∞·ª£c th·ª±c hi·ªán ƒë·ªÉ ƒë√°nh gi√° t√¨nh tr·∫°ng nghe c·ªßa c√°c binh sƒ© xe tƒÉng b·ªçc th√©p.\n\n2. EN: Pherochromocytomas is a rare disease in children with the estimated incidence is about 1 per 50.000 to 100.000 children.\n   VI: pherochromocytomas l√† m·ªôt b·ªánh hi·∫øm g·∫∑p ·ªü tr·∫ª em c√≥ t·ª∑ l·ªá m·∫Øc ∆∞·ªõc t√≠nh kho·∫£ng 1/50.000 ƒë·∫øn 100.000 tr·∫ª em.\n\n3. EN: The most common lesions are: frosted glass (91.5%), solidified (22.6%), interstitial thickening (14.2%).\n   VI: c√°c t·ªïn th∆∞∆°ng ph·ªï bi·∫øn nh·∫•t l√†: k√≠nh m·ªù (91,5%), ƒë·∫∑c (22,6%), d√†y k·∫Ω (14,2%).\n\n‚úì Saved best model (BLEU: 42.48, +1.97)\n\n============================================================\nEPOCH 3/4\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  Step 19,518/38,032 | Loss: 2.7864 | Avg: 2.9262 | LR: 2.70e-05\n  Step 20,018/38,032 | Loss: 2.8738 | Avg: 2.9292 | LR: 2.63e-05\n  Step 20,518/38,032 | Loss: 3.0195 | Avg: 2.9274 | LR: 2.56e-05\n  Step 21,018/38,032 | Loss: 3.0516 | Avg: 2.9250 | LR: 2.49e-05\n  Step 21,518/38,032 | Loss: 3.3192 | Avg: 2.9229 | LR: 2.41e-05\n  Step 22,018/38,032 | Loss: 2.9940 | Avg: 2.9218 | LR: 2.34e-05\n  Step 22,518/38,032 | Loss: 3.0014 | Avg: 2.9213 | LR: 2.27e-05\n  Step 23,018/38,032 | Loss: 2.7092 | Avg: 2.9202 | LR: 2.19e-05\n  Step 23,518/38,032 | Loss: 3.1108 | Avg: 2.9188 | LR: 2.12e-05\n  Step 24,018/38,032 | Loss: 3.0306 | Avg: 2.9166 | LR: 2.05e-05\n  Step 24,518/38,032 | Loss: 3.2113 | Avg: 2.9140 | LR: 1.97e-05\n  Step 25,018/38,032 | Loss: 2.9824 | Avg: 2.9126 | LR: 1.90e-05\n  Step 25,518/38,032 | Loss: 2.9286 | Avg: 2.9116 | LR: 1.83e-05\n  Step 26,018/38,032 | Loss: 2.9063 | Avg: 2.9099 | LR: 1.75e-05\n  Step 26,518/38,032 | Loss: 2.8366 | Avg: 2.9092 | LR: 1.68e-05\n  Step 27,018/38,032 | Loss: 2.8386 | Avg: 2.9086 | LR: 1.61e-05\n  Step 27,518/38,032 | Loss: 2.8484 | Avg: 2.9070 | LR: 1.54e-05\n  Step 28,018/38,032 | Loss: 2.6820 | Avg: 2.9062 | LR: 1.46e-05\n  Step 28,518/38,032 | Loss: 3.0085 | Avg: 2.9048 | LR: 1.39e-05\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEvaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 504/504 [00:17<00:00, 29.10it/s]","output_type":"stream"},{"name":"stdout","text":"\nEvaluating BLEU score...\n","output_type":"stream"},{"name":"stderr","text":"\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEPOCH 3 RESULTS\n============================================================\nTrain Loss:     2.9048\nVal Loss:       2.7586\nMedical BLEU:   43.20\nImprovement:    +14.60 points from baseline\nLearning Rate:  1.39e-05\nProgress:       100.0% toward target BLEU 38\nStatus:         üéâ Excellent!\n============================================================\n\nSample Medical Translations:\n1. EN: A cross-sectional descriptive study was performed to assess the hearing status of armored tank soldiers.\n   VI: nghi√™n c·ª©u m√¥ t·∫£ c·∫Øt ngang ƒë∆∞·ª£c th·ª±c hi·ªán nh·∫±m ƒë√°nh gi√° t√¨nh tr·∫°ng nghe c·ªßa c√°c binh sƒ© xe tƒÉng.\n\n2. EN: Pherochromocytomas is a rare disease in children with the estimated incidence is about 1 per 50.000 to 100.000 children.\n   VI: b·ªánh nh√¢n c√≥ t·ª∑ l·ªá m·∫Øc b·ªánh h·ªìng c·∫ßu l√† 1/50.000 ƒë·∫øn 100.000 tr·∫ª em.\n\n3. EN: The most common lesions are: frosted glass (91.5%), solidified (22.6%), interstitial thickening (14.2%).\n   VI: c√°c t·ªïn th∆∞∆°ng ph·ªï bi·∫øn nh·∫•t l√†: k√≠nh m·ªù (91,5%), ƒë·∫∑c (22,6%), d√†y k·∫Ω (14,2%).\n\n‚úì Saved best model (BLEU: 43.20, +0.72)\n\n============================================================\nEPOCH 4/4\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  Step 29,027/38,032 | Loss: 2.9173 | Avg: 2.8605 | LR: 1.32e-05\n  Step 29,527/38,032 | Loss: 2.9808 | Avg: 2.8596 | LR: 1.24e-05\n  Step 30,027/38,032 | Loss: 2.7277 | Avg: 2.8621 | LR: 1.17e-05\n  Step 30,527/38,032 | Loss: 3.0465 | Avg: 2.8627 | LR: 1.10e-05\n  Step 31,027/38,032 | Loss: 2.5584 | Avg: 2.8626 | LR: 1.02e-05\n  Step 31,527/38,032 | Loss: 2.8380 | Avg: 2.8636 | LR: 9.50e-06\n  Step 32,027/38,032 | Loss: 2.6524 | Avg: 2.8630 | LR: 8.77e-06\n  Step 32,527/38,032 | Loss: 2.5356 | Avg: 2.8638 | LR: 8.04e-06\n  Step 33,027/38,032 | Loss: 2.9771 | Avg: 2.8636 | LR: 7.31e-06\n  Step 33,527/38,032 | Loss: 3.0038 | Avg: 2.8632 | LR: 6.58e-06\n  Step 34,027/38,032 | Loss: 2.8095 | Avg: 2.8631 | LR: 5.85e-06\n  Step 34,527/38,032 | Loss: 2.8809 | Avg: 2.8622 | LR: 5.12e-06\n  Step 35,027/38,032 | Loss: 2.9554 | Avg: 2.8618 | LR: 4.39e-06\n  Step 35,527/38,032 | Loss: 3.0201 | Avg: 2.8620 | LR: 3.66e-06\n  Step 36,027/38,032 | Loss: 2.8054 | Avg: 2.8614 | LR: 2.93e-06\n  Step 36,527/38,032 | Loss: 2.7470 | Avg: 2.8605 | LR: 2.20e-06\n  Step 37,027/38,032 | Loss: 2.8618 | Avg: 2.8598 | LR: 1.47e-06\n  Step 37,527/38,032 | Loss: 2.8153 | Avg: 2.8594 | LR: 7.38e-07\n  Step 38,027/38,032 | Loss: 2.7191 | Avg: 2.8592 | LR: 7.30e-09\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEvaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 504/504 [00:17<00:00, 28.96it/s]","output_type":"stream"},{"name":"stdout","text":"\nEvaluating BLEU score...\n","output_type":"stream"},{"name":"stderr","text":"\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEPOCH 4 RESULTS\n============================================================\nTrain Loss:     2.8593\nVal Loss:       2.7439\nMedical BLEU:   43.44\nImprovement:    +14.84 points from baseline\nLearning Rate:  0.00e+00\nProgress:       100.0% toward target BLEU 38\nStatus:         üéâ Excellent!\n============================================================\n\nSample Medical Translations:\n1. EN: A cross-sectional descriptive study was performed to assess the hearing status of armored tank soldiers.\n   VI: nghi√™n c·ª©u m√¥ t·∫£ c·∫Øt ngang ƒë∆∞·ª£c th·ª±c hi·ªán nh·∫±m ƒë√°nh gi√° t√¨nh tr·∫°ng nghe c·ªßa c√°c binh sƒ© xe tƒÉng.\n\n2. EN: Pherochromocytomas is a rare disease in children with the estimated incidence is about 1 per 50.000 to 100.000 children.\n   VI: pherochromocytomas l√† m·ªôt b·ªánh hi·∫øm g·∫∑p ·ªü tr·∫ª em c√≥ t·ª∑ l·ªá m·∫Øc ∆∞·ªõc t√≠nh kho·∫£ng 1/50.000 ƒë·∫øn 100.000 tr·∫ª em.\n\n3. EN: The most common lesions are: frosted glass (91.5%), solidified (22.6%), interstitial thickening (14.2%).\n   VI: c√°c t·ªïn th∆∞∆°ng ph·ªï bi·∫øn nh·∫•t l√†: k√≠nh m·ªù (91,5%), ƒë·∫∑c (22,6%), d√†y k·∫Ω (14,2%).\n\n‚úì Saved best model (BLEU: 43.44, +0.23)\n\n============================================================\nFINE-TUNING COMPLETE!\n============================================================\n\nBest model from epoch 4\n  Medical BLEU:      43.44\n  Baseline BLEU:     28.60\n  Total improvement: +14.84 points\n  Val Loss:          2.7439\n\n============================================================\nFINAL EVALUATION\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Final Medical BLEU:    43.44\nPre-trained BLEU:      28.60\nImprovement:           +14.84 points\nGeneral BLEU target:   38.0\n\nüéâ SUCCESS! Matched/exceeded general performance!\n============================================================\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import random\n\ndef get_random_test_examples(dataset, n=50):\n    indices = random.sample(range(len(dataset['test'])), n)\n    return [dataset['test'][i]['en'] for i in indices]\n\n# Example: Sample 5 random English sentences\nmedical_examples = get_random_test_examples(dataset, n=50)\n\n\n# Sample translations\nprint(\"Sample Medical Translations:\")\nfor i, s in enumerate(medical_examples, 1):\n    translation = translate_sentence(model, tokenizer, s, device)\n    print(f\"{i}. EN: {s}\")\n    print(f\"   VI: {translation}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T14:10:37.635174Z","iopub.execute_input":"2025-12-16T14:10:37.635613Z","iopub.status.idle":"2025-12-16T14:10:48.051951Z","shell.execute_reply.started":"2025-12-16T14:10:37.635577Z","shell.execute_reply":"2025-12-16T14:10:48.051239Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Sample Medical Translations:\n1. EN: Treatment of foot drop after spinal anesthesia with intravenous lipid 20% emulsion: A case report\n   VI: ƒëi·ªÅu tr·ªã gi·∫£m b√†n ch√¢n sau g√¢y t√™ tu·ª∑ s·ªëng b·∫±ng thu·ªëc m·ª° tƒ©nh m·∫°ch 20% em nh≈© t∆∞∆°ng: b√°o c√°o ca b·ªánh\n\n2. EN: Setting up the suitable solutions in the reality made the active changes, hygiene and safe food conditions changed following to 10 standards of food sold on the street sides.\n   VI: x√¢y d·ª±ng c√°c gi·∫£i ph√°p th√≠ch h·ª£p trong th·ª±c t·∫ø ƒë√£ l√†m thay ƒë·ªïi ho·∫°t ƒë·ªông, v·ªá sinh v√† ƒëi·ªÅu ki·ªán th·ª±c ph·∫©m an to√†n thay ƒë·ªïi theo 10 ti√™u chu·∫©n th·ª±c ph·∫©m ƒë∆∞·ª£c b√°n ·ªü c√°c b√™n ƒë∆∞·ªùng ph·ªë.\n\n3. EN: Lorcaserin (not available in the US) suppresses appetite via selective agonism of serotonin 2C (5-HT2C) brain receptors.\n   VI: lorcaserin (kh√¥ng c√≥ ·ªü m·ªπ) ·ª©c ch·∫ø s·ª± th√®m ƒÉn th√¥ng qua s·ª± ch·ªß v·∫≠n ch·ªçn l·ªçc c·ªßa th·ª• th·ªÉ n√£o serotonin 2c (5-ht 2c).\n\n4. EN: The proportion of nurses with a positive attitude related to the perception of pain in the patient is still low.\n   VI: t·ª∑ l·ªá ƒëi·ªÅu d∆∞·ª°ng c√≥ th√°i ƒë·ªô t√≠ch c·ª±c li√™n quan ƒë·∫øn nh·∫≠n th·ª©c v·ªÅ ƒëau ·ªü b·ªánh nh√¢n v·∫´n c√≤n th·∫•p.\n\n5. EN: Solitary Fibrous Tumor of the chest (SFTC) is very rare, and Malignant Lipomatous Solitary Fibrous Tumor of the chest (MLSFTC) is even rarer.\n   VI: u x∆° tuy·∫øn y√™n c·ªßa ng·ª±c (sftc) r·∫•t hi·∫øm, v√† u x∆° ƒë∆°n ƒë·ªôc √°c t√≠nh c·ªßa ng·ª±c (mlsftc) th·∫≠m ch√≠ hi·∫øm h∆°n.\n\n6. EN: The purpose of this research was to identify the factors affecting customer purchase intentions toward organic food in Long Bien district, Hanoi.\n   VI: m·ª•c ti√™u c·ªßa nghi√™n c·ª©u n√†y l√† x√°c ƒë·ªãnh c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn m·ª•c ƒë√≠ch mua s·∫Øm kh√°ch h√†ng ƒë·ªëi v·ªõi th·ª±c ph·∫©m h·ªØu c∆° t·∫°i huy·ªán long bi√™n, h√† n·ªôi.\n\n7. EN: Blood glucose, renal function tests, and electrolyte levels, including calcium and magnesium, should be measured if patients have diffuse cramps of unknown cause, particularly if hyperreflexia is present.\n   VI: glucose m√°u, x√©t nghi·ªám ch·ª©c nƒÉng th·∫≠n v√† ƒëi·ªán gi·∫£i, bao g·ªìm canxi v√† magi√™, n√™n ƒë∆∞·ª£c ƒëo n·∫øu b·ªánh nh√¢n b·ªã chu·ªôt r√∫t lan to·∫£ nguy√™n nh√¢n kh√¥ng r√µ nguy√™n nh√¢n, ƒë·∫∑c bi·ªát n·∫øu tƒÉng ph·∫£n x·∫°.\n\n8. EN: Result and conclusion: The expression of 4 microRNAs: MicroRNA-146 - 3p, microRNA-147b, microRNA-155, microRNA-223 in sepsis group was significantly higher than that in healthy control and DHF group (p<0.05).\n   VI: k·∫øt qu·∫£ v√† k·∫øt lu·∫≠n: bi·ªÉu hi·ªán c·ªßa 4 micrornas: microrna-146-3p, microrna-147b, microrna-155, microrna-223 ·ªü nh√≥m nhi·ªÖm khu·∫©n huy·∫øt cao h∆°n c√≥ √Ω nghƒ©a so v·ªõi nh√≥m ch·ª©ng kho·∫ª m·∫°nh v√† dhf (p < 0,05).\n\n9. EN: In the physical and daily living, females reporting higher levels of unmet need than males, married group reporting lower levels of unmet need than lower than single / unmarried group, the self-moving group was lower than the non-self-moving group.\n   VI: ·ªü nh·ªØng ng∆∞·ªùi s·ªëng v√† h√†ng ng√†y, n·ªØ gi·ªõi b√°o c√°o m·ª©c ƒë·ªô nhu c·∫ßu kh√¥ng chuy·ªÉn ƒë·ªïi cao h∆°n nam gi·ªõi, nh√≥m k·∫øt h√¥n b√°o c√°o m·ª©c ƒë·ªô nhu c·∫ßu th·∫•p h∆°n so v·ªõi nh√≥m kh√¥ng ƒë√°p ·ª©ng th·∫•p h∆°n nh√≥m ƒë∆°n / ch∆∞a k·∫øt h√¥n, nh√≥m t·ª± di chuy·ªÉn th·∫•p h∆°n nh√≥m kh√¥ng t·ª± di chuy·ªÉn.\n\n10. EN: Results: Tertiary health service: There were 28 anaphylactic shock cases in total 32 referral cases, 26 cases (92.9%) were treated with Adrenaline, in those 26 cases there were 5 cases (19.2%) treated with IM / SC / IV Adrenaline combined with continuous IV Adrenaline.\n   VI: k·∫øt qu·∫£: c√≥ 28 tr∆∞·ªùng h·ª£p s·ªëc ph·∫£n v·ªá trong t·ªïng s·ªë 32 tr∆∞·ªùng h·ª£p, 26 tr∆∞·ªùng h·ª£p (92,9%) ƒë∆∞·ª£c ƒëi·ªÅu tr·ªã b·∫±ng adrenalin, trong 26 tr∆∞·ªùng h·ª£p c√≥ 5 tr∆∞·ªùng h·ª£p (19,2%) ƒëi·ªÅu tr·ªã b·∫±ng im / sc / iv k·∫øt h·ª£p v·ªõi adrenaline ƒë∆∞·ªùng tƒ©nh m·∫°ch li√™n t·ª•c.\n\n11. EN: Results management of fetal chromosomal abnormalities: proportion of chromosomal abnormalities was 8.2%, including 6.4% to abortion; 1.8% referral for monitoring and further treatment.\n   VI: k·∫øt qu·∫£ ƒëi·ªÅu tr·ªã b·∫•t th∆∞·ªùng nhi·ªÖm s·∫Øc th·ªÉ thai nhi: t·ª∑ l·ªá b·∫•t th∆∞·ªùng nhi·ªÖm s·∫Øc th·ªÉ l√† 8,2%, bao g·ªìm 6,4% ƒë·ªÉ ph√° thai; 1,8% ch·ªâ ƒë·ªãnh theo d√µi v√† ƒëi·ªÅu tr·ªã th√™m.\n\n12. EN: The prevanlence of overweight by weight / height index was 4.1%.\n   VI: t·ª∑ l·ªá th·ª´a c√¢n theo ch·ªâ s·ªë c√¢n / chi·ªÅu cao l√† 4,1%.\n\n13. EN: The diastolic left ventricular function improved significantly from 1 month follow-up after CRT implantation with a decrease in the E / e' index, and e', a' and s' indices were increased (p<0.05).\n   VI: ch·ª©c nƒÉng th·∫•t tr√°i t√¢m tr∆∞∆°ng c·∫£i thi·ªán ƒë√°ng k·ªÉ t·ª´ 1 th√°ng theo d√µi sau khi c·∫•y gh√©p crt v·ªõi s·ª± gi·∫£m ch·ªâ s·ªë e / e ‚Äô v√† e ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s ‚Äô s\n\n14. EN: Result: 56 patients underwent MIMVR surgery, the male-female ratio was 1: 2.1; the mean age was 44.5 ¬± 12.5 years old; Preoperative functional symptom: NYHA grade I-II in 66.1%.\n   VI: k·∫øt qu·∫£: 56 b·ªánh nh√¢n ƒë∆∞·ª£c ph·∫´u thu·∫≠t mimvr, t·ª∑ l·ªá nam-n·ªØ l√† 1: 2,1; tu·ªïi trung b√¨nh l√† 44,5 ¬± 12,5 tu·ªïi; tri·ªáu ch·ª©ng ch·ª©c nƒÉng tr∆∞·ªõc m·ªï: nyha ƒë·ªô i-ii 66,1%.\n\n15. EN: Subjects and methods: The survey was carried out in 4 provinces of Hai Duong, Lam Dong, Dong Nai, Thua Thien-Hue at 40 small and medium production facilities with a total of 894 employees (565 men; 329 women). Results: showed that 591 people, accounting for 66.11%, were exposed to harmful factors in the working environment, in which the number of men exposed was nearly twice the number of women.\n   VI: ƒë·ªëi t∆∞·ª£ng v√† ph∆∞∆°ng ph√°p: nghi√™n c·ª©u ƒë∆∞·ª£c th·ª±c hi·ªán t·∫°i 4 t·ªânh h·∫£i d∆∞∆°ng, lam ƒë√¥ng, ƒë·ªìng nai, th·ª´a thi√™n-hue t·∫°i 40 c∆° s·ªü s·∫£n xu·∫•t nh·ªè v√† trung b√¨nh v·ªõi t·ªïng s·ªë 894 nh√¢n vi√™n (565 nam; 329 n·ªØ). k·∫øt qu·∫£: 591 ng∆∞·ªùi, chi·∫øm 66,11%, ti·∫øp x√∫c v·ªõi c√°c y·∫øu t·ªë nguy h·∫°i trong m√¥i tr∆∞·ªùng lao ƒë·ªông, trong ƒë√≥ s·ªë nam gi·ªõi ti·∫øp x√∫c g·∫ßn g·∫•p ƒë√¥i s·ªë ph·ª• n·ªØ.\n\n16. EN: There have been many studies on the correlation between indirect methods to quantify LDL-cholesterol with the direct quantitative method in the world, but it is rare in Vietnam.\n   VI: c√≥ nhi·ªÅu nghi√™n c·ª©u v·ªÅ m·ªëi t∆∞∆°ng quan gi·ªØa c√°c ph∆∞∆°ng ph√°p gi√°n ti·∫øp ƒë·ªÉ ƒë·ªãnh l∆∞·ª£ng ldl-cholesterol v·ªõi ph∆∞∆°ng ph√°p ƒë·ªãnh l∆∞·ª£ng tr·ª±c ti·∫øp tr√™n th·∫ø gi·ªõi, nh∆∞ng hi·∫øm g·∫∑p ·ªü vi·ªát nam.\n\n17. EN: A study about the knowledge of relatives of pediatric epileptics on epilepsy\n   VI: nghi√™n c·ª©u ki·∫øn th·ª©c v·ªÅ ng∆∞·ªùi th√¢n ƒë·ªông kinh ·ªü tr·∫ª em\n\n18. EN: The median serum TNF-alpha levels of the patients with erythroderma were 13.77 + 4, 2 pg / mL, significantly higher than those of healthy people (p = 0.000) and of the plaque-type psoriatic patients (0.000) and patients with psoriatic arthritis (0.000).\n   VI: n·ªìng ƒë·ªô tnf-alpha huy·∫øt thanh trung v·ªã c·ªßa b·ªánh nh√¢n c√≥ erythroderma l√† 13,77 + 4,2 pg / ml, cao h∆°n ƒë√°ng k·ªÉ so v·ªõi ng∆∞·ªùi kho·∫ª m·∫°nh (p = 0,000) v√† c·ªßa b·ªánh nh√¢n v·∫£y n·∫øn d·∫°ng m·∫£ng m·∫£ng m·∫£ng (0,000) v√† b·ªánh nh√¢n vi√™m kh·ªõp v·∫£y n·∫øn (0,000).\n\n19. EN: Results: Ethanol 100 mM reduced 45.1% of HepG2 cells viability.\n   VI: k·∫øt qu·∫£: ethanol 100 mm gi·∫£m 45,1% t·∫ø b√†o gan hepg2.\n\n20. EN: For example, a patient who has mild asthma with long periods of no or mild symptoms and normal pulmonary function may have a severe, life-threatening exacerbation.\n   VI: v√≠ d·ª•, m·ªôt b·ªánh nh√¢n hen nh·∫π c√≥ c√°c tri·ªáu ch·ª©ng kh√¥ng ho·∫∑c nh·∫π v√† ch·ª©c nƒÉng ph·ªïi b√¨nh th∆∞·ªùng c√≥ th·ªÉ c√≥ ƒë·ª£t c·∫•p n·∫∑ng, ƒëe do·∫° t√≠nh m·∫°ng.\n\n21. EN: Background: Transhiatal esophagectomy (THE) is advantageous (avoiding thoracotomy, shorter operative time, smaller blood loss, decreased complications and mortality) and it is applied worldwide by surgeons.\n   VI: ƒë·∫∑t v·∫•n ƒë·ªÅ: c·∫Øt th·ª±c qu·∫£n qua sinh (the) l√† ∆∞u ƒëi·ªÉm (tr√°nh m·ªü ng·ª±c, th·ªùi gian m·ªï ng·∫Øn h∆°n, m·∫•t m√°u nh·ªè h∆°n, gi·∫£m bi·∫øn ch·ª©ng v√† t·ª≠ vong) v√† ƒë∆∞·ª£c c√°c ph·∫´u thu·∫≠t vi√™n √°p d·ª•ng tr√™n to√†n th·∫ø gi·ªõi.\n\n22. EN: Adnexal masses are often related to the menstrual cycle; they include follicular ovarian cysts (follicles that develop normally but do not release an egg) and corpus luteal cysts.\n   VI: c√°c kh·ªëi u tuy·∫øn th∆∞·ª£ng th·∫≠n th∆∞·ªùng li√™n quan ƒë·∫øn chu k·ª≥ kinh nguy·ªát; ch√∫ng bao g·ªìm nang bu·ªìng tr·ª©ng nang no√£n nang no√£n nang (c√°c nang ph√°t tri·ªÉn b√¨nh th∆∞·ªùng nh∆∞ng kh√¥ng gi·∫£i ph√≥ng tr·ª©ng) v√† nang ho√†ng th·ªÉ.\n\n23. EN: Other combined lesions include gastric mucosal inflammation (92.4%), gastric varices (26.6%), duodenal ulcer 10.1%.\n   VI: c√°c t·ªïn th∆∞∆°ng ph·ªëi h·ª£p kh√°c bao g·ªìm vi√™m ni√™m m·∫°c d·∫° d√†y (92,4%), gi√£n d·∫° d√†y (26,6%), lo√©t t√° tr√†ng 10,1%.\n\n24. EN: Patient and method of study: Study design: clinical trial with control group (30 patients for each group: study and control group).\n   VI: ƒë·ªëi t∆∞·ª£ng v√† ph∆∞∆°ng ph√°p nghi√™n c·ª©u: nghi√™n c·ª©u: th·ª≠ nghi·ªám l√¢m s√†ng v·ªõi nh√≥m ch·ª©ng (30 b·ªánh nh√¢n ƒë·ªëi v·ªõi m·ªói nh√≥m: nghi√™n c·ª©u v√† nh√≥m ch·ª©ng).\n\n25. EN: Keywords: Moyamoya disease, cerebral occlusive disease, bypass\n   VI: t·ª´ kho√°: b·ªánh moyamoya, b·ªánh t·∫Øc ngh·∫Ωn n√£o, b·∫Øc c·∫ßu\n\n26. EN: 98.6% of patients had Raynaud's phenomenon and the average process duration of Raynaud's phenomenon was 38.0 ¬± 37.2 months and the average Raynaud's condition score was 3.9 ¬± 1.5 points; 6 patients accounting for 8.5% had active digital ulcers; the average quantity of digital pitting scars was 1.1 ¬± 1.4.\n   VI: 98,6% b·ªánh nh√¢n c√≥ hi·ªán t∆∞·ª£ng raynaud v√† th·ªùi gian trung b√¨nh c·ªßa hi·ªán t∆∞·ª£ng raynaud l√† 38,0 ¬± 37,2 th√°ng v√† ƒëi·ªÉm s·ªë t√¨nh tr·∫°ng c·ªßa raynaud trung b√¨nh l√† 3,9 ¬± 1,5 ƒëi·ªÉm; 6 b·ªánh nh√¢n chi·∫øm 8,5% c√≥ v·∫øt lo√©t s·ªë l∆∞·ª£ng v·∫øt lo√©t s·ªë ho·∫°t ƒë·ªông; s·ªë s·∫πo n·∫πp s·ªë trung b√¨nh l√† 1,1 ¬± 1,4.\n\n27. EN: Two doses of Ich Tri Vuong did not effect SGOT and SGPT, while Atorvastatin induced a significant in there liver enzymes.\n   VI: hai li·ªÅu ich tri v≈©√¥ng kh√¥ng ·∫£nh h∆∞·ªüng sgot v√† sgpt, trong khi atorvastatin g√¢y ra m·ªôt s·ªë y·∫øu t·ªë ƒë√°ng k·ªÉ ·ªü ƒë√≥ c√°c enzym gan.\n\n28. EN: A cross-sectional study was conducted. The study to describe the disease pattern of in-patients in Kien Hai district hospital in 2011.\n   VI: nghi√™n c·ª©u m√¥ t·∫£ m√¥ t·∫£ m√¥ h√¨nh b·ªánh t·∫≠t b·ªánh nh√¢n t·∫°i b·ªánh vi·ªán huy·ªán ki√™n h·∫£i nƒÉm 2011.\n\n29. EN: Objective: To evaluate the results of tension-free transobturator tape surgery in treatment of femal stress urinary incontinence Methods: Between January 2011 and May 2012, 29 women underwent TOT procedures at Viet Duc University Hospital.\n   VI: m·ª•c ti√™u: ƒë√°nh gi√° k·∫øt qu·∫£ ph·∫´u thu·∫≠t n·ªôi soi ·ªï b·ª•ng kh√¥ng cƒÉng th·∫≥ng trong ƒëi·ªÅu tr·ªã c√°c ph∆∞∆°ng ph√°p kh√¥ng ki·ªÉm so√°t ƒëau th·∫Øt l∆∞ng: t·ª´ th√°ng 1/2011 ƒë·∫øn th√°ng 5/2012, 29 ph·ª• n·ªØ ƒë∆∞·ª£c ph·∫´u thu·∫≠t tot t·∫°i b·ªánh vi·ªán h·ªØu ngh·ªã vi·ªát ƒë·ª©c.\n\n30. EN: Most of spinal tumors were neurinomas and localized higher at thoracic spine.\n   VI: ƒëa s·ªë u tu·ª∑ s·ªëng l√† u th·∫ßn kinh v√† khu tr√∫ cao h∆°n ·ªü c·ªôt s·ªëng ng·ª±c.\n\n31. EN: 24h BP characteristics were compared between patients with and without LVH.\n   VI: ƒë·∫∑c ƒëi·ªÉm huy·∫øt √°p 24h ƒë∆∞·ª£c so s√°nh gi·ªØa b·ªánh nh√¢n c√≥ v√† kh√¥ng c√≥ lvh.\n\n32. EN: Prognostic factors in hand-foot-mouth disease due to enterovirus\n   VI: c√°c y·∫øu t·ªë ti√™n l∆∞·ª£ng b·ªánh tay ch√¢n mi·ªáng do enterovirus\n\n33. EN: Survey about head injury due to traffic accident in ho chi minh city after helmet wearing's resolution has done\n   VI: kh·∫£o s√°t ch·∫•n th∆∞∆°ng s·ªç n√£o do tai n·∫°n giao th√¥ng t·∫°i th√†nh ph·ªë h·ªì ch√≠ minh sau khi ƒëeo m≈© b·∫£o hi·ªÉm ƒë√£ th·ª±c hi·ªán.\n\n34. EN: These results demonstrated that gene expression is dependent on the developmental stage of the cell as well as on the dose of the chemical exposed.\n   VI: k·∫øt qu·∫£ n√†y cho th·∫•y bi·ªÉu hi·ªán gen ph·ª• thu·ªôc v√†o giai ƒëo·∫°n ph√°t tri·ªÉn c·ªßa t·∫ø b√†o c≈©ng nh∆∞ li·ªÅu ph∆°i nhi·ªÖm ho√° h·ªçc.\n\n35. EN: One in two patients was identified as carrying mutation of gene encoded succinate dehydrogenase complex iron sulfur subunit B (SDHB).\n   VI: m·ªôt trong hai b·ªánh nh√¢n ƒë∆∞·ª£c x√°c ƒë·ªãnh l√† mang ƒë·ªôt bi·∫øn gen ƒë∆∞·ª£c m√£ ho√° succinate dehydrogenase complex sulfur b (sdhb).\n\n36. EN: Objectives: To evaluate total knee replacement surgery results treating severe knee osteoarthritis at the Can Tho University of Medicine and Pharmacy Hospital.\n   VI: m·ª•c ti√™u: ƒë√°nh gi√° k·∫øt qu·∫£ ph·∫´u thu·∫≠t thay kh·ªõp g·ªëi to√†n b·ªô k·∫øt qu·∫£ ƒëi·ªÅu tr·ªã tho√°i ho√° kh·ªõp g·ªëi n·∫∑ng t·∫°i b·ªánh vi·ªán ƒë·∫°i h·ªçc y d∆∞·ª£c c·∫ßn th∆°.\n\n37. EN: Men were more at risk than women.\n   VI: nam gi·ªõi c√≥ nguy c∆° cao h∆°n n·ªØ gi·ªõi.\n\n38. EN: Accordingly, the presumptive prediction of a culprit artery based on the electrocardiogram (ECG) recorded at admission is an important clinical sign.\n   VI: theo ƒë√≥, d·ª± ƒëo√°n gi·∫£ ƒë·ªãnh c·ªßa ƒë·ªông m·∫°ch th·ªß ph·∫°m d·ª±a tr√™n ƒëi·ªán t√¢m ƒë·ªì (ecg) ƒë∆∞·ª£c ghi nh·∫≠n khi nh·∫≠p vi·ªán l√† m·ªôt d·∫•u hi·ªáu l√¢m s√†ng quan tr·ªçng.\n\n39. EN: Endoscopy results: small curvilinear ulcer, size 1 cm, surface is not smooth.\n   VI: k·∫øt qu·∫£ n·ªôi soi: lo√©t l·ªìi c·∫ßu nh·ªè, k√≠ch th∆∞·ªõc 1 cm, b·ªÅ m·∫∑t kh√¥ng tr∆°n.\n\n40. EN: Percentage of poor treatment results in combined causes groups was 37.5%, higher than the group due to refractive error alone (11.2%).\n   VI: t·ª∑ l·ªá ƒëi·ªÅu tr·ªã k√©m k·∫øt h·ª£p l√† 37,5%, cao h∆°n nh√≥m do sai s√≥t kh√∫c x·∫° ƒë∆°n thu·∫ßn (11,2%).\n\n41. EN: MCR-1 is a phosphoethanolamine transferase.\n   VI: mcr-1 l√† m·ªôt chuy·ªÉn thu·ªëc phosphoethanolamine.\n\n42. EN: Side effects only recorded 5.8% itching and 7.1% skin redness in the first week, which disappeared in the next 5 weeks of treatment.\n   VI: t√°c d·ª•ng ph·ª• ch·ªâ ghi nh·∫≠n 5,8% ng·ª©a v√† 7,1% m√†u ƒë·ªè da trong tu·∫ßn ƒë·∫ßu ti√™n, bi·∫øn m·∫•t trong 5 tu·∫ßn ti·∫øp theo.\n\n43. EN: Objective: To describe the disease structure and some related factors of the patients in the Cardiovascular Intensive Care Unit (A2-D).\n   VI: m·ª•c ti√™u: m√¥ t·∫£ c·∫•u tr√∫c b·ªánh t·∫≠t v√† m·ªôt s·ªë y·∫øu t·ªë li√™n quan c·ªßa b·ªánh nh√¢n t·∫°i khoa h·ªìi s·ª©c t√≠ch c·ª±c tim m·∫°ch (a 2-d).\n\n44. EN: The most recent way to handle risks.\n   VI: c√°ch g·∫ßn ƒë√¢y nh·∫•t ƒë·ªÉ x·ª≠ l√Ω r·ªßi ro.\n\n45. EN: Paronychia and pyogenic granuloma-like lesions are among the most noticeably undesirable side effects on patients treated with epidermal growth factor receptor inhibitor (EGFR). These badly affect the patients' quality of life as well as their compliance with targeted therapies.\n   VI: t·ªïn th∆∞∆°ng gi·ªëng nh∆∞ u h·∫°t pyogenic l√† m·ªôt trong nh·ªØng t√°c d·ª•ng ph·ª• kh√¥ng mong mu·ªën nh·∫•t tr√™n b·ªánh nh√¢n ƒëi·ªÅu tr·ªã b·∫±ng thu·ªëc ·ª©c ch·∫ø th·ª• th·ªÉ y·∫øu t·ªë tƒÉng tr∆∞·ªüng th∆∞·ª£ng b√¨ (v√≠ d·ª•:fr). nh·ªØng t·ªïn th∆∞∆°ng n√†y ·∫£nh h∆∞·ªüng x·∫•u ƒë·∫øn ch·∫•t l∆∞·ª£ng cu·ªôc s·ªëng c·ªßa b·ªánh nh√¢n c≈©ng nh∆∞ tu√¢n th·ªß c√°c li·ªáu ph√°p nh·∫Øm tr√∫ng ƒë√≠ch.\n\n46. EN: There have been many advances in diagnosis and treatment of EOC for last decades but the selection of an optimal management is still considered individual patients in their own contemporary stage of disease.\n   VI: ƒë√£ c√≥ nhi·ªÅu ti·∫øn b·ªô trong ch·∫©n ƒëo√°n v√† ƒëi·ªÅu tr·ªã eoc trong nhi·ªÅu th·∫≠p k·ª∑ qua nh∆∞ng vi·ªác l·ª±a ch·ªçn m·ªôt c√°ch ƒëi·ªÅu tr·ªã t·ªëi ∆∞u v·∫´n ƒë∆∞·ª£c coi l√† nh·ªØng b·ªánh nh√¢n ri√™ng l·∫ª trong giai ƒëo·∫°n hi·ªán ƒë·∫°i c·ªßa h·ªç.\n\n47. EN: Conclusion: Tracheal tumor resection and reconstruction surgery is feasible. Indication should reserves for tumors that invade less then one third of the trachea.\n   VI: k·∫øt lu·∫≠n: ph·∫´u thu·∫≠t c·∫Øt b·ªè kh·ªëi u v√† t√°i t·∫°o l√† kh·∫£ thi, ch·ªâ ƒë·ªãnh d·ª± tr·ªØ u x√¢m l·∫•n √≠t h∆°n 1/3 s·ªë kh√≠ qu·∫£n.\n\n48. EN: Evaluation of serum calcium, phosphorus and parathyroid hormone in hemodialysis and continuous ambulatory peritoneal dialysis patient in binh dan hospital\n   VI: ƒë√°nh gi√° n·ªìng ƒë·ªô canxi, phospho v√† hormone tuy·∫øn c·∫≠n gi√°p trong l·ªçc m√°u v√† l·ªçc m√°u li√™n t·ª•c ·ªü b·ªánh nh√¢n l·ªçc m√°u chu k·ª≥ t·∫°i b·ªánh vi·ªán b√¨nh d√¢n\n\n49. EN: From check-in reason whether hospital because the hospital trust Tu Du 63.4%, not trust medical facilities 57.4%.\n   VI: t·ª´ l√Ω do check-in li·ªáu b·ªánh vi·ªán c√≥ tin c·∫≠y t·ª´ d≈© 63,4%, kh√¥ng tin t∆∞·ªüng c∆° s·ªü y t·∫ø 57,4%.\n\n50. EN: The study recorded 5.75% of errors in the quality test and 7.13% in the herbs' form.\n   VI: nghi√™n c·ª©u ghi nh·∫≠n 5,75% sai s√≥t trong x√©t nghi·ªám ch·∫•t l∆∞·ª£ng v√† 7,13% ·ªü d·∫°ng th·∫£o d∆∞·ª£c.\n\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"translation = translate_sentence(model, tokenizer, \"Even with Dellacqua's retirement in early 2018, Barty has also continued to improve at doubles, having since won the five biggest doubles titles of her career, including her first Grand Slam title at the 2018 US Open.\", device)\nprint(translation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T14:14:19.184231Z","iopub.execute_input":"2025-12-16T14:14:19.184504Z","iopub.status.idle":"2025-12-16T14:14:19.495829Z","shell.execute_reply.started":"2025-12-16T14:14:19.184484Z","shell.execute_reply":"2025-12-16T14:14:19.495007Z"}},"outputs":[{"name":"stdout","text":"ngay c·∫£ khi ngh·ªâ h∆∞u v√†o ƒë·∫ßu nƒÉm 2018, barty c≈©ng ƒë√£ ti·∫øp t·ª•c c·∫£i thi·ªán ·ªü hai nh√≥m, t·ª´ ƒë√≥ ƒë√£ c√≥ 5 l·∫ßn ƒë·∫ßu ti√™n ƒë√°nh gi√° v·ªÅ s·ª± nghi·ªáp c·ªßa m√¨nh, bao g·ªìm c·∫£ ti√™u chu·∫©n grand) ƒë·∫ßu ti√™n c·ªßa c√¥ t·∫°i m·ªπ m·ªü.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}