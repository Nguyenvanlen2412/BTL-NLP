{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nguynvnln22028281/btl-nlp-cleandata?scriptVersionId=286613002\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install langid sentence-transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:47:07.768156Z","iopub.execute_input":"2025-12-14T01:47:07.768902Z","iopub.status.idle":"2025-12-14T01:48:45.091889Z","shell.execute_reply.started":"2025-12-14T01:47:07.768869Z","shell.execute_reply":"2025-12-14T01:48:45.089782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:48:45.095537Z","iopub.execute_input":"2025-12-14T01:48:45.095971Z","iopub.status.idle":"2025-12-14T01:48:45.696006Z","shell.execute_reply.started":"2025-12-14T01:48:45.09593Z","shell.execute_reply":"2025-12-14T01:48:45.694923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\ntrain_dataset = load_dataset(\"ncduy/mt-en-vi\", split = \"train\")\n\nvalid_dataset = load_dataset(\"ncduy/mt-en-vi\", split = \"validation\")\n\ntest_dataset = load_dataset(\"ncduy/mt-en-vi\", split = \"test\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:54:53.243621Z","iopub.execute_input":"2025-12-14T01:54:53.24466Z","iopub.status.idle":"2025-12-14T01:54:54.240913Z","shell.execute_reply.started":"2025-12-14T01:54:53.244619Z","shell.execute_reply":"2025-12-14T01:54:54.23979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = train_dataset.shuffle(seed=42).select(range(1000000))\nprint(len(train_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:55:17.253903Z","iopub.execute_input":"2025-12-14T01:55:17.254543Z","iopub.status.idle":"2025-12-14T01:55:17.582181Z","shell.execute_reply.started":"2025-12-14T01:55:17.254512Z","shell.execute_reply":"2025-12-14T01:55:17.581364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom tqdm import tqdm\nimport re\nimport unicodedata\nimport langid\nimport torch\n\n# ENABLE semantic filtering for medical data\nuse_semantic_filter = False\nsimilarity_threshold = 0.70  # Raised for technical content\n\nif use_semantic_filter:\n    from sentence_transformers import SentenceTransformer, util\n    print(\"Loading LaBSE model...\")\n    labse = SentenceTransformer(\"sentence-transformers/LaBSE\")\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    labse = labse.to(device)\n\n# ---------------------------\n# Enhanced Cleaning Functions\n# ---------------------------\n\ndef normalize_text(s):\n    # Remove HTML/XML\n    s = re.sub(r\"<[^>]+>\", \"\", s)\n\n    # Unicode normalize (this is SAFE)\n    s = unicodedata.normalize(\"NFC\", s)\n\n    # Remove zero-width chars\n    s = s.replace(\"\\u200b\", \"\").replace(\"\\ufeff\", \"\")\n\n    # Fix spacing\n    s = re.sub(r'\\s+([.,;:!?])', r'\\1', s)\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n\n    return s\n\ndef is_metadata_line(s):\n    \"\"\"Detect non-content lines (headers, page numbers, etc.)\"\"\"\n    s_lower = s.lower()\n    \n    # Check for common metadata patterns\n    metadata_patterns = [\n        r'^page \\d+$',\n        r'^\\d+\\s*$',  # Just numbers\n        r'^(abstract|introduction|conclusion|references?|methods?):\\s*$',\n        r'^\\w+\\s+\\d{4}$',  # \"December 2021\"\n        r'^volume \\d+',\n        r'^doi:',\n        r'^issn',\n        r'^copyright',\n    ]\n    \n    for pattern in metadata_patterns:\n        if re.match(pattern, s_lower):\n            return True\n    \n    # Too short to be meaningful content\n    if len(s.split()) < 4:\n        return True\n        \n    return False\n\ndef heuristic_bad_pair(en, vi):\n    \"\"\"Enhanced domain-specific filters\"\"\"\n    en_low = en.lower()\n    vi_low = vi.lower()\n    \n    # Known translation errors in this dataset\n    if \"vaginal\" in en_low and any(kw in en_low for kw in [\"ear\", \"otitis\", \"tympanogram\"]):\n        return True\n    \n    # Corrupted spellings\n    if any(bad in en_low for bad in [\"otittis\", \"rhinolaryngology\", \"imumnohistochemistry\"]):\n        return True\n    \n    # Detect if one side is metadata but other isn't\n    if is_metadata_line(en) != is_metadata_line(vi):\n        return True\n    \n    # Both are metadata\n    if is_metadata_line(en) and is_metadata_line(vi):\n        return True\n    \n    # Check for URL/email mismatches\n    en_has_url = bool(re.search(r'https?://|www\\.', en))\n    vi_has_url = bool(re.search(r'https?://|www\\.', vi))\n    if en_has_url != vi_has_url:\n        return True\n    \n    # Detect if one sentence has numbers/stats but other doesn't\n    en_has_nums = bool(re.search(r'\\d+[.,]?\\d*\\s*[%±]', en))\n    vi_has_nums = bool(re.search(r'\\d+[.,]?\\d*\\s*[%±]', vi))\n    # Allow medical texts with stats on one side (could be rephrased)\n    # But reject if one has LOTS of numbers and other has none\n    en_num_count = len(re.findall(r'\\d+', en))\n    vi_num_count = len(re.findall(r'\\d+', vi))\n    if en_num_count > 5 and vi_num_count == 0:\n        return True\n    if vi_num_count > 5 and en_num_count == 0:\n        return True\n    \n    return False\n\ndef length_ratio_bad(en, vi):\n    \"\"\"Stricter length constraints for medical abstracts\"\"\"\n    len_en, len_vi = len(en.split()), len(vi.split())\n    \n    # Minimum length (medical sentences are usually substantial)\n    if len_en < 3 or len_vi < 3:\n        return True\n    \n    # Maximum length (likely concatenated paragraphs)\n    if len_en > 150 or len_vi > 150:\n        return True\n    \n    # Tighter ratio for technical content\n    ratio = len_en / max(len_vi, 1)\n    if ratio > 2 or ratio < 0.5:\n        return True\n    return False\n\ndef language_mismatch(en, vi):\n    \"\"\"Relaxed language detection for medical text\"\"\"\n    # Medical text may be unreliable for langid - use as soft signal\n    try:\n        lang_en, score_en = langid.classify(en)\n        lang_vi, score_vi = langid.classify(vi)\n        \n        # Only reject on very confident misdetections\n        if score_en > 0.9 and lang_en != \"en\":\n            return True\n        if score_vi > 0.9 and lang_vi != \"vi\":\n            return True\n            \n    except Exception:\n        # If langid fails, don't reject\n        pass\n    \n    # Additional heuristic: Vietnamese should have tone marks\n    vietnamese_chars = set(\"áàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệíìỉĩịóòỏõọôốồổỗộơớờởỡợúùủũụưứừửữựýỳỷỹỵđ\")\n    vi_lower = vi.lower()\n    has_vietnamese_chars = any(c in vietnamese_chars for c in vi_lower)\n    \n    # Reject if supposed Vietnamese has zero tone marks (likely English)\n    if len(vi_lower) > 20 and not has_vietnamese_chars:\n        return True\n    \n    return False\n\ndef semantic_bad(en, vi):\n    \"\"\"Compute semantic similarity with batching for speed\"\"\"\n    with torch.no_grad():\n        emb_en = labse.encode(en, convert_to_tensor=True, device=device)\n        emb_vi = labse.encode(vi, convert_to_tensor=True, device=device)\n        score = util.cos_sim(emb_en, emb_vi).item()\n    return score < similarity_threshold\n\n\n# ---------------------------\n# Dataset Class\n# ---------------------------\nclass ParallelTextDataset(Dataset):\n    def __init__(self, hf_dataset):\n        self.data = []\n        seen = set()\n        rejected_length_samples = []\n        \n        \n        stats = {\n            'total': 0,\n            'empty': 0,\n            'heuristic': 0,\n            'length': 0,\n            'language': 0,\n            'semantic': 0,\n            'duplicate': 0,\n            'kept': 0\n        }\n\n        for item in tqdm(hf_dataset, desc=\"CLeaning HF dataset\"):\n            src = item[\"en\"].strip()\n            tgt = item[\"vi\"].strip()\n            stats[\"total\"] += 1\n\n            if not src or not tgt:\n                stats[\"empty\"] += 1\n                continue\n                \n            #normalize\n            en = normalize_text(src)\n            vi = normalize_text(tgt)\n\n            if not en or not vi:\n                stats[\"empty\"] += 1\n                continue\n                \n            # Filter pipeline\n            if heuristic_bad_pair(en, vi):\n                stats['heuristic'] += 1\n                continue\n            \n            if length_ratio_bad(en, vi):\n                if len(rejected_length_samples) < 20:  # Collect 20 samples\n                    rejected_length_samples.append({\n                        'en': en,\n                        'vi': vi,\n                        'len_en': len(en.split()),\n                        'len_vi': len(vi.split()),\n                        'ratio': len(en.split()) / max(len(vi.split()), 1)\n                    })\n                stats['length'] += 1\n                continue\n            \n            if language_mismatch(en, vi):\n                stats['language'] += 1\n                continue\n            \n            if use_semantic_filter and semantic_bad(en, vi):\n                stats['semantic'] += 1\n                continue\n            \n            # Deduplicate\n            key = en + \"|||\" + vi\n            if key in seen:\n                stats['duplicate'] += 1\n                continue\n            \n            seen.add(key)\n            self.data.append((en, vi))\n            stats['kept'] += 1\n    \n        # Print detailed statistics\n        print(f\"\\n{'='*60}\")\n#        print(f\"Dataset: {src_file.split('/')[-1]}\")\n        print(f\"{'='*60}\")\n        print(f\"Total pairs processed:     {stats['total']:>6}\")\n        print(f\"  - Empty/blank:           {stats['empty']:>6} ({stats['empty']/stats['total']*100:>5.1f}%)\")\n        print(f\"  - Heuristic filters:     {stats['heuristic']:>6} ({stats['heuristic']/stats['total']*100:>5.1f}%)\")\n        print(f\"  - Length ratio:          {stats['length']:>6} ({stats['length']/stats['total']*100:>5.1f}%)\")\n        print(f\"  - Language mismatch:     {stats['language']:>6} ({stats['language']/stats['total']*100:>5.1f}%)\")\n        if use_semantic_filter:\n            print(f\"  - Semantic similarity:   {stats['semantic']:>6} ({stats['semantic']/stats['total']*100:>5.1f}%)\")\n        print(f\"  - Duplicates:            {stats['duplicate']:>6} ({stats['duplicate']/stats['total']*100:>5.1f}%)\")\n        print(f\"{'='*60}\")\n        print(f\"CLEAN PAIRS KEPT:          {stats['kept']:>6} ({stats['kept']/stats['total']*100:>5.1f}%)\")\n        print(f\"{'='*60}\\n\")\n\n        print(\"\\n\" + \"=\"*60)\n        print(\"SAMPLE REJECTED PAIRS (Length Ratio):\")\n        print(\"=\"*60)\n        for i, sample in enumerate(rejected_length_samples[:10], 1):\n            print(f\"\\n--- Sample {i} ---\")\n            print(f\"EN ({sample['len_en']} words): {sample['en'][:150]}...\")\n            print(f\"VI ({sample['len_vi']} words): {sample['vi'][:150]}...\")\n            print(f\"Ratio: {sample['ratio']:.2f}\")\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        return self.data[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T02:35:11.081729Z","iopub.execute_input":"2025-12-14T02:35:11.082083Z","iopub.status.idle":"2025-12-14T02:35:11.115004Z","shell.execute_reply.started":"2025-12-14T02:35:11.082059Z","shell.execute_reply":"2025-12-14T02:35:11.114084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------------------\n# Usage\n# ---------------------------\ntrain_dataset = ParallelTextDataset(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T02:36:11.446532Z","iopub.execute_input":"2025-12-14T02:36:11.446866Z","iopub.status.idle":"2025-12-14T03:13:06.55745Z","shell.execute_reply.started":"2025-12-14T02:36:11.446844Z","shell.execute_reply":"2025-12-14T03:13:06.556286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_dataset = ParallelTextDataset(valid_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T03:13:06.560485Z","iopub.execute_input":"2025-12-14T03:13:06.560799Z","iopub.status.idle":"2025-12-14T03:13:30.57015Z","shell.execute_reply.started":"2025-12-14T03:13:06.560776Z","shell.execute_reply":"2025-12-14T03:13:30.56901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = ParallelTextDataset(test_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T02:35:18.073569Z","iopub.execute_input":"2025-12-14T02:35:18.073905Z","iopub.status.idle":"2025-12-14T02:35:41.886643Z","shell.execute_reply.started":"2025-12-14T02:35:18.073883Z","shell.execute_reply":"2025-12-14T02:35:41.885634Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test it\nfor i in range(10):\n    src, tgt = test_dataset[i]\n    print(f\"Source: {src}\")\n    print(f\"Target: {tgt}\")\n\nprint(len(test_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T02:36:06.01357Z","iopub.execute_input":"2025-12-14T02:36:06.014829Z","iopub.status.idle":"2025-12-14T02:36:06.020901Z","shell.execute_reply.started":"2025-12-14T02:36:06.014784Z","shell.execute_reply":"2025-12-14T02:36:06.01983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\ndef save_to_jsonl(dataset, filename):\n    with open(filename, 'w', encoding='utf-8') as f:\n        for en, vi in dataset.data:\n            json_line = json.dumps({\"en\": en, \"vi\": vi}, ensure_ascii=False)\n            f.write(json_line + '\\n')\n\nsave_to_jsonl(train_dataset, \"train_cleaned.jsonl\")\nsave_to_jsonl(valid_dataset, \"valid_cleaned.jsonl\")\n\nsave_to_jsonl(test_dataset, \"test_cleaned.jsonl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T03:15:31.681225Z","iopub.execute_input":"2025-12-14T03:15:31.681732Z","iopub.status.idle":"2025-12-14T03:15:39.850118Z","shell.execute_reply.started":"2025-12-14T03:15:31.681702Z","shell.execute_reply":"2025-12-14T03:15:39.849147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}