{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46595302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:25:26.232214Z",
     "iopub.status.busy": "2025-12-12T15:25:26.231599Z",
     "iopub.status.idle": "2025-12-12T15:25:28.013113Z",
     "shell.execute_reply": "2025-12-12T15:25:28.012231Z"
    },
    "papermill": {
     "duration": 1.788834,
     "end_time": "2025-12-12T15:25:28.014448",
     "exception": false,
     "start_time": "2025-12-12T15:25:26.225614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/btl-nlp-cleandata/test_cleaned.jsonl\n",
      "/kaggle/input/btl-nlp-cleandata/train_cleaned.jsonl\n",
      "/kaggle/input/btl-nlp-cleandata/__results__.html\n",
      "/kaggle/input/btl-nlp-cleandata/__notebook__.ipynb\n",
      "/kaggle/input/btl-nlp-cleandata/__output__.json\n",
      "/kaggle/input/btl-nlp-cleandata/custom.css\n",
      "/kaggle/input/btl-nlp-cleandata/.virtual_documents/__notebook_source__.ipynb\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2951e185",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:25:28.023967Z",
     "iopub.status.busy": "2025-12-12T15:25:28.023539Z",
     "iopub.status.idle": "2025-12-12T15:25:38.074761Z",
     "shell.execute_reply": "2025-12-12T15:25:38.074052Z"
    },
    "papermill": {
     "duration": 10.057342,
     "end_time": "2025-12-12T15:25:38.075914",
     "exception": false,
     "start_time": "2025-12-12T15:25:28.018572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f678bd3de24afcb8b39c984d65c2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c761496eed4f5d80c14b70ec35f096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Final dataset structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['en', 'vi'],\n",
      "        num_rows: 305942\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['en', 'vi'],\n",
      "        num_rows: 16103\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['en', 'vi'],\n",
      "        num_rows: 2793\n",
      "    })\n",
      "})\n",
      "  Train: 305942 pairs\n",
      "  Validation: 16103 pairs\n",
      "  Test: 2793 pairs\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "\n",
    "\n",
    "# Load data\n",
    "data_files = {\n",
    "    \"train\": \"/kaggle/input/btl-nlp-cleandata/train_cleaned.jsonl\",\n",
    "    \"test\": \"/kaggle/input/btl-nlp-cleandata/test_cleaned.jsonl\"\n",
    "}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "# Create train/validation split (90/10 or 95/5)\n",
    "train_val_split = dataset['train'].train_test_split(\n",
    "    test_size=0.05,  # 5% for validation\n",
    "    seed=42,\n",
    "    shuffle=True  # IMPORTANT: Shuffle the data\n",
    ")\n",
    "\n",
    "# Reassemble into final dataset structure\n",
    "dataset = DatasetDict({\n",
    "    'train': train_val_split['train'],\n",
    "    'validation': train_val_split['test'],  # Note: this is validation, not test\n",
    "    'test': dataset['test']\n",
    "})\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Final dataset structure:\")\n",
    "print(dataset)\n",
    "print(f\"  Train: {len(dataset['train'])} pairs\")\n",
    "print(f\"  Validation: {len(dataset['validation'])} pairs\")\n",
    "print(f\"  Test: {len(dataset['test'])} pairs\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a2896ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:25:38.085900Z",
     "iopub.status.busy": "2025-12-12T15:25:38.085540Z",
     "iopub.status.idle": "2025-12-12T15:25:38.096172Z",
     "shell.execute_reply": "2025-12-12T15:25:38.095547Z"
    },
    "papermill": {
     "duration": 0.016752,
     "end_time": "2025-12-12T15:25:38.097166",
     "exception": false,
     "start_time": "2025-12-12T15:25:38.080414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET INSPECTION\n",
      "============================================================\n",
      "\n",
      "TRAIN split:\n",
      "  Total examples: 305942\n",
      "\n",
      "  Example 4464:\n",
      "    EN (28 words): Background: Robot-assisted surgery was first employed by the end of 1980s, and has since become popu...\n",
      "    VI (34 words): Đặt vấn đề: Phẫu thuật có hổ trợ robot lần đầu tiên được tiến hành tại Mỹ vào cuối thập niên 1980 và...\n",
      "\n",
      "  Example 28853:\n",
      "    EN (6 words): Plasma homocysteine levels in lupus erythematosus...\n",
      "    VI (10 words): Nồng độ homocysteine huyết tương trên bệnh nhânlupus ban đỏ...\n",
      "\n",
      "  Example 202115:\n",
      "    EN (22 words): Effects of low dose chitosan combined MAP packaging on respiratory rate, disease prevention and colo...\n",
      "    VI (30 words): Ảnh hưởng chitosan liều thấp kết hợp bao bì MAP đến tốc độ hô hấp, tỉ lệ nấm bệnh và màu sắc vỏ tron...\n",
      "\n",
      "  Example 251292:\n",
      "    EN (22 words): Results: In Vĩnh Kim and Ia Kor, malaria is transmitted all - year round, with one high peak from Se...\n",
      "    VI (25 words): Kết quả: Tại Vĩnh Kim và Ia Kor mùa truyền bệnh sốt rét quanh năm, thường có 1 đỉnh vào tháng 9 đến ...\n",
      "\n",
      "  Example 77822:\n",
      "    EN (36 words): Case report: We present two cases of a 47-year-old female and 34-year-old with no medical history, a...\n",
      "    VI (48 words): Báo cáo ca bệnh: Chúng tôi báo cáo hai trường hợp bệnh nhân nữ 47 tuổi và 37 tuổi, tiền sử khoẻ mạnh...\n",
      "\n",
      "VALIDATION split:\n",
      "  Total examples: 16103\n",
      "\n",
      "  Example 2937:\n",
      "    EN (26 words): Methods: The records of 15 consecutive patients who underwent percutaneous interlaminar endoscopic d...\n",
      "    VI (49 words): Đối tượng và phương pháp nghiên cứu: 15 bệnh nhân được phẫu thuật nội soi liên bản sống điều trị bện...\n",
      "\n",
      "  Example 2230:\n",
      "    EN (17 words): Background: The increasing of antibiotic resistance in H pylori has become a main cause for treatmen...\n",
      "    VI (23 words): Đặt vấn đề: Sự gia tăng tình trạng kháng kháng sinh của H. pylori là nguyên nhân chính gây thất bại ...\n",
      "\n",
      "  Example 6511:\n",
      "    EN (24 words): Subjects and Methods: 29 patients with recurrent dislocations of the shoulder underwent MR arthrogra...\n",
      "    VI (32 words): Đối tượng và phương pháp nghiên cứu: 29 bệnh nhân trật khớp vai tái hồi được chụp CHT có tiêm tương ...\n",
      "\n",
      "  Example 3775:\n",
      "    EN (17 words): Incidence of epilepsy and seizures, headache and facial pain were higher in those younger than 60 ye...\n",
      "    VI (19 words): Tỷ lệ động kinh / co giật, đau đầu / mặt cao hơn ở nhóm tuổi < 60 tuổi....\n",
      "\n",
      "  Example 6487:\n",
      "    EN (6 words): CEA and Calcitonin level were high....\n",
      "    VI (5 words): CEA và Calcitonin máu tăng....\n",
      "\n",
      "TEST split:\n",
      "  Total examples: 2793\n",
      "\n",
      "  Example 191:\n",
      "    EN (5 words): In Vietnam, Gomphrena celosioides Mart....\n",
      "    VI (6 words): Nở ngày đất (Gomphrena celosioides Mart....\n",
      "\n",
      "  Example 1248:\n",
      "    EN (22 words): This was a retrospective and prospective study, blood pressure was measured daily before and early p...\n",
      "    VI (36 words): Nghiên cứu được tiến hành theo phương pháp hồi cứu kết hợp tiến cứu, huyết áp của các người bệnh đượ...\n",
      "\n",
      "  Example 449:\n",
      "    EN (12 words): Some factors related to treatment compliance of patients with type 2 diabetes...\n",
      "    VI (20 words): Một số yếu tố liên quan đến sự tuân thủ điều trị của bệnh nhân đái tháo đường typ 2...\n",
      "\n",
      "  Example 298:\n",
      "    EN (32 words): Patients were satisfied more with mental health services (77.8%), nursing care skills (75.5%) and th...\n",
      "    VI (52 words): Người bệnh hài lòng về công tác chăm sóc tinh thần (77,8%), kỹ năng chuyên môn của điều dưỡng, hộ si...\n",
      "\n",
      "  Example 831:\n",
      "    EN (29 words): Results: The study on 260 patients recorded: the overall satisfaction rate of patients was 74.2%, th...\n",
      "    VI (32 words): Kết quả: Nghiên cứu trên 260 người bệnh (NB) ghi nhận: tỉ lệ hài lòng chung của NB là 74,2%, điểm tr...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def inspect_dataset(dataset, num_samples=5):\n",
    "    \"\"\"Inspect random samples from dataset\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATASET INSPECTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check for None/empty values\n",
    "    for split in dataset.keys():\n",
    "        print(f\"\\n{split.upper()} split:\")\n",
    "        print(f\"  Total examples: {len(dataset[split])}\")\n",
    "        \n",
    "        # Sample random examples\n",
    "        indices = random.sample(range(len(dataset[split])), min(num_samples, len(dataset[split])))\n",
    "        \n",
    "        for idx in indices:\n",
    "            example = dataset[split][idx]\n",
    "            en = example['en']\n",
    "            vi = example['vi']\n",
    "            \n",
    "            print(f\"\\n  Example {idx}:\")\n",
    "            print(f\"    EN ({len(en.split())} words): {en[:100]}...\")\n",
    "            print(f\"    VI ({len(vi.split())} words): {vi[:100]}...\")\n",
    "            \n",
    "            # Sanity checks\n",
    "            if not en or not vi:\n",
    "                print(\"    ⚠️  WARNING: Empty field detected!\")\n",
    "            if len(en.split()) < 3 or len(vi.split()) < 3:\n",
    "                print(\"    ⚠️  WARNING: Very short sentence!\")\n",
    "\n",
    "inspect_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c4e595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:25:38.107016Z",
     "iopub.status.busy": "2025-12-12T15:25:38.106463Z",
     "iopub.status.idle": "2025-12-12T15:25:55.668116Z",
     "shell.execute_reply": "2025-12-12T15:25:55.667306Z"
    },
    "papermill": {
     "duration": 17.567677,
     "end_time": "2025-12-12T15:25:55.669400",
     "exception": false,
     "start_time": "2025-12-12T15:25:38.101723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CHECKING DATA LEAKAGE\n",
      "============================================================\n",
      "Train unique EN sentences: 304773\n",
      "Test unique EN sentences: 2793\n",
      "Overlap: 1646\n",
      "⚠️  WARNING: 1646 test sentences also in train!\n",
      "Sample overlapping sentences:\n",
      "  - Common clinical features: fatigue (99.4%); anorexia, poor appetite (97.1%); collateral circulation (...\n",
      "  - Subject and method: A cross-sectional study on 600 inpatients at Hue University of Medicine and Phar...\n",
      "  - Results: 42.6% of mothers had knowledge that the route of transmission was from eating or drinking c...\n"
     ]
    }
   ],
   "source": [
    "def check_data_leakage(dataset):\n",
    "    \"\"\"Check if test examples appear in train\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CHECKING DATA LEAKAGE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    train_en = set(ex['en'] for ex in dataset['train'])\n",
    "    test_en = set(ex['en'] for ex in dataset['test'])\n",
    "    \n",
    "    overlap = train_en & test_en\n",
    "    \n",
    "    print(f\"Train unique EN sentences: {len(train_en)}\")\n",
    "    print(f\"Test unique EN sentences: {len(test_en)}\")\n",
    "    print(f\"Overlap: {len(overlap)}\")\n",
    "    \n",
    "    if overlap:\n",
    "        print(f\"⚠️  WARNING: {len(overlap)} test sentences also in train!\")\n",
    "        print(\"Sample overlapping sentences:\")\n",
    "        for sent in list(overlap)[:3]:\n",
    "            print(f\"  - {sent[:100]}...\")\n",
    "    else:\n",
    "        print(\"✅ No data leakage detected\")\n",
    "\n",
    "check_data_leakage(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb3b3cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:25:55.679330Z",
     "iopub.status.busy": "2025-12-12T15:25:55.678831Z",
     "iopub.status.idle": "2025-12-12T15:25:59.034804Z",
     "shell.execute_reply": "2025-12-12T15:25:59.034108Z"
    },
    "papermill": {
     "duration": 3.362124,
     "end_time": "2025-12-12T15:25:59.036016",
     "exception": false,
     "start_time": "2025-12-12T15:25:55.673892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REMOVING TRAIN ITEMS THAT ALSO APPEAR IN TEST (HF DATASET)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9d27fc65434b3681ed5c8e8e5c6656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/305942 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train size: 305942\n",
      "New train size     : 304286\n",
      "Removed from train : 1656\n",
      "✅ Train cleaned and test set unchanged.\n"
     ]
    }
   ],
   "source": [
    "def remove_train_overlaps(dataset):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REMOVING TRAIN ITEMS THAT ALSO APPEAR IN TEST (HF DATASET)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Extract English sentences from test split\n",
    "    test_en = set(dataset['test']['en'])   # fast and HF compatible\n",
    "\n",
    "    old_size = len(dataset['train'])\n",
    "\n",
    "    # Use .filter() to keep only examples not in test\n",
    "    dataset['train'] = dataset['train'].filter(\n",
    "        lambda ex: ex['en'] not in test_en\n",
    "    )\n",
    "\n",
    "    new_size = len(dataset['train'])\n",
    "    removed = old_size - new_size\n",
    "\n",
    "    print(f\"Original train size: {old_size}\")\n",
    "    print(f\"New train size     : {new_size}\")\n",
    "    print(f\"Removed from train : {removed}\")\n",
    "\n",
    "    if removed > 0:\n",
    "        print(\"✅ Train cleaned and test set unchanged.\")\n",
    "    else:\n",
    "        print(\"No overlaps found.\")\n",
    "\n",
    "    return dataset\n",
    "dataset = remove_train_overlaps(dataset)\n",
    "\n",
    "# Reassemble final dataset\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset['train'],\n",
    "    'validation': train_val_split['test'],  # your val set\n",
    "    'test': dataset['test']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01ff713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:25:59.046348Z",
     "iopub.status.busy": "2025-12-12T15:25:59.046119Z",
     "iopub.status.idle": "2025-12-12T15:26:51.191942Z",
     "shell.execute_reply": "2025-12-12T15:26:51.191069Z"
    },
    "papermill": {
     "duration": 52.152677,
     "end_time": "2025-12-12T15:26:51.193275",
     "exception": false,
     "start_time": "2025-12-12T15:25:59.040598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "        TRAINING EN–VI MEDICAL BYTE-LEVEL TOKENIZER\n",
      "======================================================================\n",
      "\n",
      "1. Preparing training corpus...\n",
      "2. Initializing byte-level BPE tokenizer...\n",
      "3. Configuring BPE trainer...\n",
      "4. Training tokenizer on corpus (vocab=32000)...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5. Saving tokenizer to: medical_envi_tokenizer/\n",
      "\n",
      "6. Testing tokenizer with sample medical text:\n",
      "\n",
      "Text: The patient has SARS-CoV-2 infection.\n",
      "Tokens: ['the', 'Ġpatient', 'Ġhas', 'Ġsars', '-', 'cov', '-', '2', 'Ġinfection', '.']\n",
      "IDs: [2, 2407, 1060, 1140, 5216, 18, 4875, 18, 23, 1063, 19, 3]\n",
      "\n",
      "Text: Bệnh nhân bị viêm phổi do vi khuẩn Streptococcus pneumoniae.\n",
      "Tokens: ['bá»ĩnh', 'ĠnhÃ¢n', 'Ġbá»ĭ', 'ĠviÃªm', 'Ġphá»ķi', 'Ġdo', 'Ġvi', 'Ġkhuáº©n', 'Ġstreptococcus', 'Ġpneumoniae', '.']\n",
      "IDs: [2, 5736, 415, 793, 741, 973, 573, 470, 1186, 6793, 4084, 19, 3]\n",
      "\n",
      "Text: CT scan shows pulmonary edema and pleural effusion.\n",
      "Tokens: ['ct', 'Ġscan', 'Ġshows', 'Ġpulmonary', 'Ġedema', 'Ġand', 'Ġpleural', 'Ġeffusion', '.']\n",
      "IDs: [2, 1120, 3313, 4075, 2043, 3871, 327, 4940, 5104, 19, 3]\n",
      "\n",
      "Text: Huyết áp 120/80 mmHg, SpO2 95%, nhịp tim 110 bpm.\n",
      "Tokens: ['huyáº¿t', 'ĠÃ¡p', 'Ġ120', '/', '80', 'Ġmmhg', ',', 'Ġspo', '2', 'Ġ95', '%,', 'Ġnhá»ĭp', 'Ġtim', 'Ġ110', 'Ġbpm', '.']\n",
      "IDs: [2, 17981, 969, 4735, 20, 3588, 3996, 17, 7296, 23, 1678, 626, 2239, 631, 7260, 24180, 19, 3]\n",
      "\n",
      "======================================================================\n",
      "✅ Tokenizer trained successfully!\n",
      "   Final vocab size: 32000\n",
      "   Saved to: medical_envi_tokenizer/\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers, processors\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from datasets import DatasetDict\n",
    "from tokenizers import decoders\n",
    "\n",
    "def train_medical_tokenizer(\n",
    "    dataset: DatasetDict,\n",
    "    vocab_size: int = 32000,\n",
    "    save_path: str = \"tokenizer_medical_envi\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a robust byte-level BPE tokenizer optimized for EN-VI medical translation.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"        TRAINING EN–VI MEDICAL BYTE-LEVEL TOKENIZER\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1. Build corpus generator\n",
    "    # --------------------------------------------------------\n",
    "    print(\"\\n1. Preparing training corpus...\")\n",
    "\n",
    "    train_iter = dataset[\"train\"].to_iterable_dataset()\n",
    "\n",
    "    def corpus_generator():\n",
    "        for ex in train_iter:\n",
    "            if \"en\" in ex and ex[\"en\"]:\n",
    "                yield ex[\"en\"]\n",
    "            if \"vi\" in ex and ex[\"vi\"]:\n",
    "                yield ex[\"vi\"]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2. Create tokenizer\n",
    "    # --------------------------------------------------------\n",
    "    print(\"2. Initializing byte-level BPE tokenizer...\")\n",
    "\n",
    "    tokenizer = Tokenizer(\n",
    "    models.BPE(unk_token=\"<unk>\", byte_fallback=True)\n",
    "    )\n",
    "    # --- normalization pipeline ---\n",
    "    tokenizer.normalizer = normalizers.Sequence([\n",
    "        normalizers.NFD(),       # fully decompose (Vietnamese safe)\n",
    "        normalizers.Lowercase(), # lowercase everything\n",
    "        normalizers.NFC(),       # recompose\n",
    "        normalizers.Strip(),     # remove leading/trailing whitespace\n",
    "    ])\n",
    "\n",
    "    # --- byte-level pretokenizer ---\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
    "    # Add this line to your tokenizer setup\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3. Trainer configuration\n",
    "    # --------------------------------------------------------\n",
    "    print(\"3. Configuring BPE trainer...\")\n",
    "\n",
    "    special_tokens = [\n",
    "        \"<pad>\", \"<unk>\", \"<s>\", \"</s>\",\n",
    "        \"<en>\", \"<vi>\"   # language tags\n",
    "    ]\n",
    "\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=vocab_size,\n",
    "        min_frequency=2,\n",
    "        special_tokens=special_tokens,\n",
    "        initial_alphabet=pre_tokenizers.ByteLevel.alphabet(),\n",
    "        show_progress=True,\n",
    "    )\n",
    "    # --------------------------------------------------------\n",
    "    # 4. Training\n",
    "    # --------------------------------------------------------\n",
    "    print(f\"4. Training tokenizer on corpus (vocab={vocab_size})...\")\n",
    "    tokenizer.train_from_iterator(corpus_generator(), trainer=trainer)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5. Post-processing (add <s> and </s> automatically)\n",
    "    # --------------------------------------------------------\n",
    "    tokenizer.post_processor = processors.TemplateProcessing(\n",
    "        single=\"<s> $A </s>\",\n",
    "        pair=\"<s> $A </s> <s> $B </s>\",\n",
    "        special_tokens=[\n",
    "            (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "            (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 6. Wrap as HF tokenizer\n",
    "    # --------------------------------------------------------\n",
    "    wrapped = PreTrainedTokenizerFast(\n",
    "        tokenizer_object=tokenizer,\n",
    "        bos_token=\"<s>\",\n",
    "        eos_token=\"</s>\",\n",
    "        pad_token=\"<pad>\",\n",
    "        unk_token=\"<unk>\",\n",
    "        additional_special_tokens=[\"<en>\", \"<vi>\"],\n",
    "        model_max_length=512,\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7. Save\n",
    "    # --------------------------------------------------------\n",
    "    print(f\"\\n5. Saving tokenizer to: {save_path}/\")\n",
    "    wrapped.save_pretrained(save_path)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 8. Test samples\n",
    "    # --------------------------------------------------------\n",
    "    print(\"\\n6. Testing tokenizer with sample medical text:\")\n",
    "\n",
    "    tests = [\n",
    "        \"The patient has SARS-CoV-2 infection.\",\n",
    "        \"Bệnh nhân bị viêm phổi do vi khuẩn Streptococcus pneumoniae.\",\n",
    "        \"CT scan shows pulmonary edema and pleural effusion.\",\n",
    "        \"Huyết áp 120/80 mmHg, SpO2 95%, nhịp tim 110 bpm.\",\n",
    "    ]\n",
    "\n",
    "    for t in tests:\n",
    "        print(\"\\nText:\", t)\n",
    "        print(\"Tokens:\", wrapped.tokenize(t))\n",
    "        print(\"IDs:\", wrapped.encode(t))\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"✅ Tokenizer trained successfully!\")\n",
    "    print(f\"   Final vocab size: {wrapped.vocab_size}\")\n",
    "    print(f\"   Saved to: {save_path}/\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    return wrapped\n",
    "tokenizer = train_medical_tokenizer( dataset, vocab_size=32000, save_path=\"medical_envi_tokenizer\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1f4939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.204452Z",
     "iopub.status.busy": "2025-12-12T15:26:51.203873Z",
     "iopub.status.idle": "2025-12-12T15:26:51.209269Z",
     "shell.execute_reply": "2025-12-12T15:26:51.208523Z"
    },
    "papermill": {
     "duration": 0.012089,
     "end_time": "2025-12-12T15:26:51.210350",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.198261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Ở trẻ sơ sinh bị hẹp van động mạch phổi nghiêm trọng, xanh tím xuất hiện do luồng thông ở tâm nhĩ từ phải sang trái thông qua lỗ bầu dục.\n",
      "Tokens: ['á»Ł', 'Ġtráº»', 'ĠsÆ¡', 'Ġsinh', 'Ġbá»ĭ', 'Ġháº¹p', 'Ġvan', 'ĠÄĳá»Ļng', 'Ġmáº¡ch', 'Ġphá»ķi', 'ĠnghiÃªm', 'Ġtrá»įng', ',', 'Ġxanh', 'ĠtÃŃm', 'Ġxuáº¥t', 'Ġhiá»ĩn', 'Ġdo', 'Ġluá»ĵng', 'ĠthÃ´ng', 'Ġá»Ł', 'ĠtÃ¢m', 'ĠnhÄ©', 'Ġtá»«', 'Ġpháº£i', 'Ġsang', 'ĠtrÃ¡i', 'ĠthÃ´ng', 'Ġqua', 'Ġlá»Ĺ', 'Ġbáº§u', 'Ġdá»¥c', '.']\n",
      "IDs: [399, 773, 1753, 581, 793, 2416, 2066, 684, 645, 973, 2749, 1330, 17, 5261, 5919, 1117, 624, 573, 10344, 1007, 446, 1132, 2669, 549, 1037, 3317, 2161, 1007, 1041, 3277, 11881, 2029, 19]\n"
     ]
    }
   ],
   "source": [
    "text = dataset[\"train\"][0][\"vi\"]\n",
    "tokens = tokenizer.tokenize(text)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(\"Text:\", text)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"IDs:\", ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17391d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.220480Z",
     "iopub.status.busy": "2025-12-12T15:26:51.220012Z",
     "iopub.status.idle": "2025-12-12T15:26:51.225837Z",
     "shell.execute_reply": "2025-12-12T15:26:51.225179Z"
    },
    "papermill": {
     "duration": 0.011872,
     "end_time": "2025-12-12T15:26:51.226831",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.214959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ở trẻ sơ sinh bị hẹp van động mạch phổi nghiêm trọng, xanh tím xuất hiện do luồng thông ở tâm nhĩ từ phải sang trái thông qua lỗ bầu dục.\n",
      "Decoded text: ở trẻ sơ sinh bị hẹp van động mạch phổi nghiêm trọng, xanh tím xuất hiện do luồng thông ở tâm nhĩ từ phải sang trái thông qua lỗ bầu dục.\n",
      "--- DIFFERENCE DETECTED ---\n",
      "Original: Ở trẻ sơ sinh bị hẹp van động mạch phổi nghiêm trọng, xanh tím xuất hiện do luồng thông ở tâm nhĩ từ phải sang trái thông qua lỗ bầu dục.\n",
      "Decoded:  ở trẻ sơ sinh bị hẹp van động mạch phổi nghiêm trọng, xanh tím xuất hiện do luồng thông ở tâm nhĩ từ phải sang trái thông qua lỗ bầu dục.\n"
     ]
    }
   ],
   "source": [
    "# 1. Paste the FULL list of IDs from your first message here:\n",
    "ids = [\n",
    "    399, 773, 1753, 581, 793, 2416, 2066, 684, 645, 973, 2749, 1330, \n",
    "    17, 5261, 5919, 1117, 624, 573, 10344, 1007, 446, 1132, 2669, \n",
    "    549, 1037, 3317, 2161, 1007, 1041, 3277, 11881, 2029, 19\n",
    "]\n",
    "\n",
    "# 2. Your original text for comparison\n",
    "original_text = \"Ở trẻ sơ sinh bị hẹp van động mạch phổi nghiêm trọng, xanh tím xuất hiện do luồng thông ở tâm nhĩ từ phải sang trái thông qua lỗ bầu dục.\"\n",
    "\n",
    "# 3. Decode back\n",
    "# Make sure 'tokenizer' is already defined and loaded!\n",
    "# Now try decoding again\n",
    "decoded_text = tokenizer.decode(ids)\n",
    "print(decoded_text)\n",
    "\n",
    "\n",
    "print(\"Decoded text:\", decoded_text)\n",
    "\n",
    "# 4. Check\n",
    "# Note: strip() is often needed because some tokenizers add a start/end space\n",
    "if decoded_text.strip() == original_text.strip():\n",
    "    print(\"SUCCESS: The data is perfect for training.\")\n",
    "else:\n",
    "    print(\"--- DIFFERENCE DETECTED ---\")\n",
    "    print(\"Original:\", original_text)\n",
    "    print(\"Decoded: \", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae83f407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.236831Z",
     "iopub.status.busy": "2025-12-12T15:26:51.236442Z",
     "iopub.status.idle": "2025-12-12T15:26:51.242014Z",
     "shell.execute_reply": "2025-12-12T15:26:51.241348Z"
    },
    "papermill": {
     "duration": 0.011782,
     "end_time": "2025-12-12T15:26:51.243148",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.231366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch  # You also need this for torch.tensor inside __getitem__\n",
    "# ============================================================================\n",
    "# DATASET CLASS\n",
    "# ============================================================================\n",
    "class TranslationDataset(Dataset):\n",
    "    \"\"\"Dataset for EN-VI medical translation\"\"\"\n",
    "    def __init__(self, dataset, tokenizer, max_len=512):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.bos_id = tokenizer.bos_token_id\n",
    "        self.eos_id = tokenizer.eos_token_id\n",
    "        self.pad_id = tokenizer.pad_token_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        \n",
    "        # Tokenize\n",
    "        src_ids = self.tokenizer.encode(item['en'], add_special_tokens=True, max_length=self.max_len, truncation=True)\n",
    "        tgt_ids = self.tokenizer.encode(item['vi'], add_special_tokens=True, max_length=self.max_len, truncation=True)\n",
    "        \n",
    "        return {\n",
    "            'src': torch.tensor(src_ids, dtype=torch.long),\n",
    "            'tgt': torch.tensor(tgt_ids, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e64b1416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.254162Z",
     "iopub.status.busy": "2025-12-12T15:26:51.253774Z",
     "iopub.status.idle": "2025-12-12T15:26:51.257908Z",
     "shell.execute_reply": "2025-12-12T15:26:51.257244Z"
    },
    "papermill": {
     "duration": 0.010152,
     "end_time": "2025-12-12T15:26:51.258903",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.248751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch, pad_id=0):\n",
    "    \"\"\"Collate function with dynamic padding\"\"\"\n",
    "    src_batch = [item['src'] for item in batch]\n",
    "    tgt_batch = [item['tgt'] for item in batch]\n",
    "    \n",
    "    # Pad sequences\n",
    "    src_padded = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=pad_id)\n",
    "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=pad_id)\n",
    "    \n",
    "    return {\n",
    "        'src': src_padded,\n",
    "        'tgt': tgt_padded\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01f4e67e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.269019Z",
     "iopub.status.busy": "2025-12-12T15:26:51.268467Z",
     "iopub.status.idle": "2025-12-12T15:26:51.274769Z",
     "shell.execute_reply": "2025-12-12T15:26:51.274092Z"
    },
    "papermill": {
     "duration": 0.01255,
     "end_time": "2025-12-12T15:26:51.275949",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.263399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================================\n",
    "# POSITIONAL ENCODING\n",
    "# ============================================================================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Sinusoidal positional encoding for transformer\"\"\"\n",
    "    def __init__(self, d_model, max_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Create positional encoding matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                            (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97575e68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.285901Z",
     "iopub.status.busy": "2025-12-12T15:26:51.285537Z",
     "iopub.status.idle": "2025-12-12T15:26:51.294155Z",
     "shell.execute_reply": "2025-12-12T15:26:51.293585Z"
    },
    "papermill": {
     "duration": 0.014684,
     "end_time": "2025-12-12T15:26:51.295191",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.280507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MULTI-HEAD ATTENTION\n",
    "# ============================================================================\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-head self-attention mechanism\"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        \"\"\"Split into multiple heads: (batch, seq_len, d_model) -> (batch, num_heads, seq_len, d_k)\"\"\"\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        return x.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "    \n",
    "    def combine_heads(self, x):\n",
    "        \"\"\"Combine heads: (batch, num_heads, seq_len, d_k) -> (batch, seq_len, d_model)\"\"\"\n",
    "        batch_size, num_heads, seq_len, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query, key, value: (batch_size, seq_len, d_model)\n",
    "            mask: (batch_size, 1, seq_len, seq_len) or (batch_size, 1, 1, seq_len)\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        # Linear projections and split heads\n",
    "        Q = self.split_heads(self.W_q(query))  # (batch, num_heads, seq_len, d_k)\n",
    "        K = self.split_heads(self.W_k(key))\n",
    "        V = self.split_heads(self.W_v(value))\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        attn_output = torch.matmul(attn_weights, V)  # (batch, num_heads, seq_len, d_k)\n",
    "        \n",
    "        # Combine heads and final linear\n",
    "        attn_output = self.combine_heads(attn_output)  # (batch, seq_len, d_model)\n",
    "        output = self.W_o(attn_output)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d8e2912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.304834Z",
     "iopub.status.busy": "2025-12-12T15:26:51.304634Z",
     "iopub.status.idle": "2025-12-12T15:26:51.308577Z",
     "shell.execute_reply": "2025-12-12T15:26:51.308078Z"
    },
    "papermill": {
     "duration": 0.009943,
     "end_time": "2025-12-12T15:26:51.309544",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.299601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEED FORWARD NETWORK\n",
    "# ============================================================================\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\"Position-wise feed-forward network\"\"\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15488100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.319715Z",
     "iopub.status.busy": "2025-12-12T15:26:51.319528Z",
     "iopub.status.idle": "2025-12-12T15:26:51.324156Z",
     "shell.execute_reply": "2025-12-12T15:26:51.323635Z"
    },
    "papermill": {
     "duration": 0.011236,
     "end_time": "2025-12-12T15:26:51.325168",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.313932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ENCODER LAYER\n",
    "# ============================================================================\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"Single encoder layer with self-attention and feed-forward\"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        # Self-attention with residual connection\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout1(attn_output))\n",
    "        \n",
    "        # Feed-forward with residual connection\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout2(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da4ff84a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.334802Z",
     "iopub.status.busy": "2025-12-12T15:26:51.334606Z",
     "iopub.status.idle": "2025-12-12T15:26:51.339899Z",
     "shell.execute_reply": "2025-12-12T15:26:51.339417Z"
    },
    "papermill": {
     "duration": 0.011364,
     "end_time": "2025-12-12T15:26:51.340888",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.329524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DECODER LAYER\n",
    "# ============================================================================\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"Single decoder layer with self-attention, cross-attention, and feed-forward\"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        # Self-attention on target\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout1(attn_output))\n",
    "        \n",
    "        # Cross-attention on encoder output\n",
    "        cross_attn_output = self.cross_attn(x, encoder_output, encoder_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout2(cross_attn_output))\n",
    "        \n",
    "        # Feed-forward\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout3(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f8e4b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.350801Z",
     "iopub.status.busy": "2025-12-12T15:26:51.350607Z",
     "iopub.status.idle": "2025-12-12T15:26:51.359988Z",
     "shell.execute_reply": "2025-12-12T15:26:51.359489Z"
    },
    "papermill": {
     "duration": 0.015568,
     "end_time": "2025-12-12T15:26:51.360994",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.345426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRANSFORMER MODEL\n",
    "# ============================================================================\n",
    "class TransformerTranslator(nn.Module):\n",
    "    \"\"\"Complete Transformer model for EN-VI medical translation\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        d_model=512,\n",
    "        num_heads=8,\n",
    "        num_encoder_layers=6,\n",
    "        num_decoder_layers=6,\n",
    "        d_ff=2048,\n",
    "        max_len=512,\n",
    "        dropout=0.1,\n",
    "        pad_idx=0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        # Embeddings\n",
    "        self.encoder_embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n",
    "        self.decoder_embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len, dropout)\n",
    "        \n",
    "        # Encoder and Decoder stacks\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_decoder_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_projection = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights using Xavier uniform\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    def make_src_mask(self, src):\n",
    "        \"\"\"Create padding mask for source: (batch, 1, 1, src_len)\"\"\"\n",
    "        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "    \n",
    "    def make_tgt_mask(self, tgt):\n",
    "        \"\"\"Create causal mask for target: (batch, 1, tgt_len, tgt_len)\"\"\"\n",
    "        batch_size, tgt_len = tgt.size()\n",
    "        \n",
    "        # Padding mask\n",
    "        tgt_pad_mask = (tgt != self.pad_idx).unsqueeze(1).unsqueeze(2)  # (batch, 1, 1, tgt_len)\n",
    "        \n",
    "        # Causal mask (lower triangular)\n",
    "        tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()\n",
    "        tgt_sub_mask = tgt_sub_mask.unsqueeze(0).unsqueeze(0)  # (1, 1, tgt_len, tgt_len)\n",
    "        \n",
    "        tgt_mask = tgt_pad_mask & tgt_sub_mask\n",
    "        return tgt_mask\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        \"\"\"Encode source sequence\"\"\"\n",
    "        # Embedding + positional encoding\n",
    "        x = self.encoder_embedding(src) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "        \n",
    "        # Pass through encoder layers\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x, src_mask)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def decode(self, tgt, encoder_output, src_mask, tgt_mask):\n",
    "        \"\"\"Decode target sequence\"\"\"\n",
    "        # Embedding + positional encoding\n",
    "        x = self.decoder_embedding(tgt) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoding(x)\n",
    "        \n",
    "        # Pass through decoder layers\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: (batch_size, src_len)\n",
    "            tgt: (batch_size, tgt_len)\n",
    "        Returns:\n",
    "            output: (batch_size, tgt_len, vocab_size)\n",
    "        \"\"\"\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        tgt_mask = self.make_tgt_mask(tgt)\n",
    "        \n",
    "        encoder_output = self.encode(src, src_mask)\n",
    "        decoder_output = self.decode(tgt, encoder_output, src_mask, tgt_mask)\n",
    "        \n",
    "        output = self.output_projection(decoder_output)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdfd65e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.370836Z",
     "iopub.status.busy": "2025-12-12T15:26:51.370660Z",
     "iopub.status.idle": "2025-12-12T15:26:51.377004Z",
     "shell.execute_reply": "2025-12-12T15:26:51.376502Z"
    },
    "papermill": {
     "duration": 0.012582,
     "end_time": "2025-12-12T15:26:51.377994",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.365412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING FUNCTION\n",
    "# ============================================================================\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, grad_clip=1.0):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in pbar:\n",
    "        src = batch['src'].to(device)\n",
    "        tgt = batch['tgt'].to(device)\n",
    "        \n",
    "        # Teacher forcing: use tgt[:-1] as input, predict tgt[1:]\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src, tgt_input)  # (batch, tgt_len-1, vocab_size)\n",
    "        \n",
    "        # Compute loss\n",
    "        output = output.reshape(-1, output.size(-1))\n",
    "        tgt_output = tgt_output.reshape(-1)\n",
    "        loss = criterion(output, tgt_output)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            src = batch['src'].to(device)\n",
    "            tgt = batch['tgt'].to(device)\n",
    "            \n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "            \n",
    "            output = model(src, tgt_input)\n",
    "            \n",
    "            output = output.reshape(-1, output.size(-1))\n",
    "            tgt_output = tgt_output.reshape(-1)\n",
    "            loss = criterion(output, tgt_output)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf8b9a0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:51.387519Z",
     "iopub.status.busy": "2025-12-12T15:26:51.387328Z",
     "iopub.status.idle": "2025-12-12T15:26:56.812821Z",
     "shell.execute_reply": "2025-12-12T15:26:56.812078Z"
    },
    "papermill": {
     "duration": 5.431803,
     "end_time": "2025-12-12T15:26:56.814194",
     "exception": false,
     "start_time": "2025-12-12T15:26:51.382391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\r\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu)\r\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2025.11.3)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\r\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\r\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\r\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\r\n",
      "Installing collected packages: portalocker, sacrebleu\r\n",
      "Successfully installed portalocker-3.2.0 sacrebleu-2.5.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c37bb33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:56.825526Z",
     "iopub.status.busy": "2025-12-12T15:26:56.825273Z",
     "iopub.status.idle": "2025-12-12T15:26:56.830699Z",
     "shell.execute_reply": "2025-12-12T15:26:56.829976Z"
    },
    "papermill": {
     "duration": 0.012378,
     "end_time": "2025-12-12T15:26:56.831789",
     "exception": false,
     "start_time": "2025-12-12T15:26:56.819411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_sentence(model, tokenizer, sentence, device, max_len=100):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize input\n",
    "    encoded = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=False,\n",
    "        truncation=True\n",
    "    )\n",
    "    src = encoded[\"input_ids\"].to(device)\n",
    "\n",
    "    # Decode using greedy search\n",
    "    pred_ids = greedy_decode(model, src, tokenizer, max_len=max_len)[0].tolist()\n",
    "\n",
    "    # Trim at EOS\n",
    "    if tokenizer.eos_token_id in pred_ids:\n",
    "        pred_ids = pred_ids[:pred_ids.index(tokenizer.eos_token_id)]\n",
    "\n",
    "    # Convert to text\n",
    "    translation = tokenizer.decode(pred_ids, skip_special_tokens=True)\n",
    "    return translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c732da17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:56.842787Z",
     "iopub.status.busy": "2025-12-12T15:26:56.842094Z",
     "iopub.status.idle": "2025-12-12T15:26:56.847678Z",
     "shell.execute_reply": "2025-12-12T15:26:56.847095Z"
    },
    "papermill": {
     "duration": 0.012081,
     "end_time": "2025-12-12T15:26:56.848657",
     "exception": false,
     "start_time": "2025-12-12T15:26:56.836576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.', 'Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.', 'This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.', 'Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.', 'All patients underwent CABG without using cardio-pulmonary bypass support.']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def get_random_test_examples(dataset, n=5):\n",
    "    indices = random.sample(range(len(dataset['test'])), n)\n",
    "    return [dataset['test'][i]['en'] for i in indices]\n",
    "\n",
    "# Example: Sample 5 random English sentences\n",
    "medical_examples = get_random_test_examples(dataset, n=5)\n",
    "\n",
    "print(medical_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22e8cc03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:26:56.859612Z",
     "iopub.status.busy": "2025-12-12T15:26:56.859429Z",
     "iopub.status.idle": "2025-12-12T23:07:11.340364Z",
     "shell.execute_reply": "2025-12-12T23:07:11.339294Z"
    },
    "papermill": {
     "duration": 27614.488461,
     "end_time": "2025-12-12T23:07:11.341984",
     "exception": false,
     "start_time": "2025-12-12T15:26:56.853523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Model Parameters: 57,601,280\n",
      "\n",
      "============================================================\n",
      "Epoch 1/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:26<00:00,  7.06it/s, loss=3.7837]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 4.5540\n",
      "Val Loss  : 3.5345\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả phẫu thuật cắt lớp vi tính của phẫu thuật nội soi cắt lớp vi tính có thể được thực hiện trong phẫu thuật cắt tuyến giáp.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: tỷ lệ bệnh nhân có kiến thức, thái độ, thái độ, thái độ, thái độ, thực hành đúng về phòng ngừa bệnh, điều trị tại bệnh viện đa khoa tỉnh thái nguyên.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: đối tượng và phương pháp nghiên cứu: nghiên cứu tiến cứu, tiến cứu, tiến cứu, tiến hành trên 60 bệnh nhân được điều trị bằng phương pháp nội soi và điều trị bằng phương pháp nội soi.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: đối tượng và phương pháp nghiên cứu: nghiên cứu mô tả cắt ngang, có 100% số lượng nước tiểu, 100% số lượng nước tiểu, 100% số lượng nước tiểu, 100% và 0,5% số lượng nước tiểu có thể được sử dụng để xác định bằng phương pháp đo lượng nước tiểu.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: đối tượng và phương pháp nghiên cứu: nghiên cứu hồi cứu, hồi cứu trên 60 bệnh nhân có biến chứng.\n",
      "---\n",
      "✓ Saved best model (val_loss=3.5345)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:27<00:00,  7.06it/s, loss=2.9054]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.4009\n",
      "Val Loss  : 3.0531\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả phẫu thuật cắt tuyến vú bằng vạt da cơ thắt lưng bằng vạt da cơ thắt lưng.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân suy dinh dưỡng có tỷ lệ bệnh nhân cao tuổi, bệnh viện, bệnh viện đa khoa tỉnh thái bình là rất quan trọng, cần có sự cải thiện chất lượng cuộc sống của bệnh nhân.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: đối tượng và phương pháp nghiên cứu: nghiên cứu hồi cứu, tiến cứu, tiến cứu, tiến hành trên bệnh nhân suy tim cấp và điều trị tại thời điểm 1 tuần.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: đối với các chất ức chế men chuyển hoá, chất ức chế men chuyển hoá (d) và chất ức chế men chuyển (d) được xác định bằng phương pháp hplc (d) với liều cao (d) 10 mg / kg / kg / ngày, 5 mg / kg / ngày, 5 mg / kg / ngày, 5 mg / kg / ngày, 5 mg / kg / kg / ngày.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: bệnh nhân được phẫu thuật tim mạch bằng máy tạo nhịp tim.\n",
      "---\n",
      "✓ Saved best model (val_loss=3.0531)\n",
      "\n",
      "============================================================\n",
      "Epoch 3/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:25<00:00,  7.06it/s, loss=2.7405]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 3.0378\n",
      "Val Loss  : 2.7999\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả phẫu thuật cắt bỏ tuyến vú bằng vạt da cơ thanh ở bệnh nhân ung thư vú giai đoạn sớm.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân suy dinh dưỡng có tỷ lệ suy dinh dưỡng cao, cần chú ý đến chăm sóc dinh dưỡng, chăm sóc dinh dưỡng, bệnh nhân có chất lượng cuộc sống tốt, giảm chất lượng cuộc sống.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu được thực hiện trên bệnh nhân sau phẫu thuật và sau đó được theo dõi và theo dõi sau 6 tuần, sau đó là huyết áp.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: kết quả: nồng độ ethanol từ 0,5 đến 0,5 mg / kg và 2 lần / ngày trong dịch chiết từ lá cây (d) đến 0,5% (d) và 0,5% (d) trên mô hình gây viêm màng não bằng phương pháp hplc.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân đều được phẫu thuật tim mạch không xâm lấn cơ tim.\n",
      "---\n",
      "✓ Saved best model (val_loss=2.7999)\n",
      "\n",
      "============================================================\n",
      "Epoch 4/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:25<00:00,  7.07it/s, loss=2.7499]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 2.8125\n",
      "Val Loss  : 2.6388\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả phẫu thuật cắt bỏ vú bằng vạt da cơ ngực dưới đòn có cuống rốn ở người trưởng thành.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân suy dinh dưỡng có tình trạng dinh dưỡng cao, có thể được điều trị kịp thời, giảm nhu cầu chăm sóc dinh dưỡng, giảm albumin máu, giảm albumin máu, giảm albumin máu.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: phương pháp nghiên cứu: nghiên cứu hồi cứu, theo dõi dọc, theo dõi dọc sau 6 tháng và 12 tháng.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: kết quả: cao chiết ethanol từ lá cây lá chùm ngây (5,5%) và cao chiết ethanol từ lá chùm ngây (5,5%) được chiết xuất từ lá chùm ngây bằng phương pháp chiết xuất từ lá chùm ngây (0,5 mg / kg, 3,5 mg / kg, 3,5 mg / kg).\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật tim hở van hai lá không xâm lấn.\n",
      "---\n",
      "✓ Saved best model (val_loss=2.6388)\n",
      "\n",
      "============================================================\n",
      "Epoch 5/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:28<00:00,  7.05it/s, loss=2.4391]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 2.6415\n",
      "Val Loss  : 2.4273\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả phẫu thuật tạo hình vú bằng vạt da cơ ngực dưới vú trong cắt vú lành tính.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân nhập viện có tình trạng dinh dưỡng cao, có thể điều trị bảo tồn, giảm nhu cầu chăm sóc dinh dưỡng và chăm sóc sức khoẻ cho người bệnh là rất tốt.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu được tiến hành nhằm đánh giá tình trạng huyết áp và huyết áp trước và sau điều trị, sau đó là ngày thứ 2 và ngày thứ 6.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: cao chiết từ lá cây gai được chiết xuất từ lá cây gai đen, với nồng độ ức chế c-l-l-l-lượng tinh khiết (0,5 mg / ml) và các chất đối kháng với các chủng vi khuẩn này có khả năng ức chế sự phân huỷ của các dòng tế bào t (0,5 mg / ml, 2,5 mg / ml, 5,5 mg / ml) và 0,5 mg / ml (0,5 mg /\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật tim hở không xâm lấn cơ tim.\n",
      "---\n",
      "✓ Saved best model (val_loss=2.4273)\n",
      "\n",
      "============================================================\n",
      "Epoch 6/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:27<00:00,  7.06it/s, loss=2.2410]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 2.3881\n",
      "Val Loss  : 2.0851\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả điều trị phẫu thuật ung thư vú có cuống glisson dưới đòn có cuống glisson dưới da.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân nhập viện điều trị suy dinh dưỡng thể nặng, cải thiện tình trạng dinh dưỡng, giúp cải thiện tình trạng dinh dưỡng, chăm sóc sức khoẻ, chăm sóc sức khoẻ và chăm sóc sức khoẻ của người bệnh là 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu, mô tả, huyết áp được thực hiện trước và sau ghép thận.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: các tế bào được điều chế bằng phương pháp chiết tách chiết từ lá cây gai và ethyl acetate (cao chiết từ lá cây lá cây gai) với hàm lượng 0,5 µg / ml, 5,2 µg / ml, 2,5 µg / ml, 3,5 mg / kg, 3,5 mg / kg, 3g / kg, 3g / kg, 3g / kg, 3g / 100 mg / kg, 3 giờ.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu động mạch chủ không sử dụng máy tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=2.0851)\n",
      "\n",
      "============================================================\n",
      "Epoch 7/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:28<00:00,  7.05it/s, loss=2.1606]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 2.0979\n",
      "Val Loss  : 1.8413\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả phẫu thuật tái tạo vú bằng vạt nhánh xuyên cuống vú trong điều trị ung thư vú có sẹo mổ thấp.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân nhập viện điều trị xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng dinh dưỡng, chăm sóc dinh dưỡng hợp lý, chăm sóc sức khoẻ hợp lý chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu, tiến cứu, mô tả, huyết áp được đo hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: tế bào gốc được điều chế bằng ethanol, ethyl acetat hoặc 70% trong các cao chiết từ vỏ quả tương ứng với curcumin ở 2,5, 5,5 và 10 µg / ml (1,2), hoặc kết hợp với ethanol 100 mg / kg trong 24 giờ.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu nối chủ vành có sử dụng máy tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.8413)\n",
      "\n",
      "============================================================\n",
      "Epoch 8/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:26<00:00,  7.06it/s, loss=1.3924]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.9082\n",
      "Val Loss  : 1.7130\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả phẫu thuật tái tạo vú bằng vạt da cuống mạch vú hai cuống liền tại bệnh viện ung bướu nghệ an.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân nhập viện điều trị xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng sức khoẻ, chăm sóc dinh dưỡng hợp lý chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu và tiến cứu, huyết áp được đo hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: tế bào gốc được điều chế bằng phương pháp chiết xuất, ethyl acetate hoặc 70% cao chiết từ thân rễ nghệ trắng tương ứng với curcumin ở nồng độ 2,5, 5 và 10 µg / ml (1,2,3) hoặc phối hợp với ethanol 100 mg / kg trong 24 giờ.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu động mạch chủ không sử dụng tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.7130)\n",
      "\n",
      "============================================================\n",
      "Epoch 9/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:26<00:00,  7.06it/s, loss=1.3944]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.7768\n",
      "Val Loss  : 1.6282\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả phẫu thuật tái tạo vú bằng vạt da nhánh xuyên cuống liền ở bệnh nhân ung thư vú có sẹo mổ thấp.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân nhập viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng sức khoẻ thể chất, chăm sóc sức khoẻ hợp lý chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: đây là nghiên cứu hồi cứu và tiến cứu, huyết áp được đo hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: các tế bào được điều chế bằng curcumin, ethyl acetate hoặc 70% chiết xuất từ thân rễ cây gai đen tương ứng với curcumin ở nồng độ 2,5, 5 và 10 µg / ml (1,2 -0,3) đơn độc hoặc kết hợp với ethanol 100 mg / g trong 24 giờ.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả các bệnh nhân được phẫu thuật bắc cầu động mạch chủ không sử dụng tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.6282)\n",
      "\n",
      "============================================================\n",
      "Epoch 10/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:28<00:00,  7.05it/s, loss=1.5062]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.6791\n",
      "Val Loss  : 1.5591\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả tái tạo vú bằng vạt da nhánh xuyên cuống mạch liền trong điều trị ung thư vú có sẹo bụng thấp.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân nhập viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể chất, điều kiện chăm sóc chung đúng chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu, tiến cứu, mô tả, huyết áp được đo hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: tế bào được điều chế bằng curcumin, ethyl acetate hoặc 70% cao chiết từ thân rễ cây nghệ thu được ở nồng độ tương ứng với curcumin lần lượt là 2,5 và 10 µg / ml (1,2 -3) đơn độc hoặc kết hợp với ethanol trong 24h.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu động mạch chủ không sử dụng tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.5591)\n",
      "\n",
      "============================================================\n",
      "Epoch 11/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:29<00:00,  7.05it/s, loss=1.9383]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.6039\n",
      "Val Loss  : 1.5181\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả tạo hình vú bằng vạt da nhánh xuyên hai cuống mạch trong điều trị ung thư vú có sẹo bụng dưới.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: người bệnh nhập viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể chất, chăm sóc chung đúng cách chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu, tiến cứu, mô tả, huyết áp được đo hàng ngày trước và sau ghép, 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: các tế bào được điều chế bằng cách bào chế với hàm lượng curcumin, ethyl acetate hoặc 70% cao chiết từ thân rễ cây nghệ có tác dụng tương ứng với ứng dụng của curcumin ở nồng độ 2,5, 5 và 10 µg / ml (1,2,3) đơn độc hoặc kết hợp với ethanol 100 mm trong 24 giờ.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả các bệnh nhân được phẫu thuật bắc cầu nối chủ vành không sử dụng tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.5181)\n",
      "\n",
      "============================================================\n",
      "Epoch 12/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:27<00:00,  7.05it/s, loss=1.4942]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.5439\n",
      "Val Loss  : 1.4826\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả tạo hình vú bằng vạt da cuống liền cuống mạch vú trong điều trị ung thư vú có sẹo bụng dưới.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: người bệnh nhập viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể lực, và các hoạt động chăm sóc chung đúng chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu và tiến cứu, huyết áp được đo hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: tế bào được điều chế bằng curcumin, ethyl acetate hoặc 70% cao chiết ethanol từ thân rễ nghệ vàng tương ứng với curcumin ở nồng độ 2,5,5 và 10 µg / ml (1,2,3) đơn độc hoặc kết hợp với ethanol 100 mm trong 24h.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu động mạch vành không sử dụng tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.4826)\n",
      "\n",
      "============================================================\n",
      "Epoch 13/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:33<00:00,  7.02it/s, loss=1.5046]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.4938\n",
      "Val Loss  : 1.4533\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả tái tạo vú bằng vạt da nhánh xuyên động mạch vú cùng bên ở bệnh nhân ung thư vú có sẹo bụng dưới.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân nhập viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể chất, và các hoạt động chăm sóc chung đúng chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: đây là nghiên cứu hồi cứu, tiến cứu, mô tả, tiến cứu, theo dõi dọc, huyết áp được đo hàng ngày trước và sau ghép, 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: các tế bào được điều trị với curcumin, ethyl acetate hoặc 70% cao chiết từ thân rễ củ nghệ ở nồng độ tương ứng với curcumin ở các nồng độ 2,5, 5 và 10 µg / ml (p < 0,01, e3) đơn thuần hoặc kết hợp với ethanol 100 mm trong 24 giờ.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu động mạch vành không sử dụng hỗ trợ tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.4533)\n",
      "\n",
      "============================================================\n",
      "Epoch 14/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:31<00:00,  7.04it/s, loss=1.5557]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.4529\n",
      "Val Loss  : 1.4270\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả tái tạo vú bằng vạt da cuống liền hai bên ở bệnh nhân ung thư vú có sẹo bụng thấp.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân nhập viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể chất, và các hoạt động chăm sóc sức khoẻ tổng quát chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu và tiến cứu, huyết áp được đo hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: tế bào được điều trị bằng curcumin, ethyl acetate hoặc 70% cao chiết ethanol từ thân rễ nghệ trắng tương ứng với curcumin ở các nồng độ 2,5, 5 và 10 µg / ml (1,2,3) đơn thuần hoặc kết hợp với ethanol 100 mm trong 24 giờ.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả các bệnh nhân được phẫu thuật bắc cầu động mạch vành không sử dụng hỗ trợ tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.4270)\n",
      "\n",
      "============================================================\n",
      "Epoch 15/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:31<00:00,  7.04it/s, loss=1.5042]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.4184\n",
      "Val Loss  : 1.4201\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả tạo hình vú bằng vạt cuống liền hai bên ở bệnh nhân ung thư vú có sẹo vùng bụng dưới.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: người bệnh vào viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể chất, và hoạt động chăm sóc chung đúng chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: đây là nghiên cứu hồi cứu và tiến cứu, huyết áp được đo hàng ngày trước và sau ghép sớm, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: các tế bào được điều trị cho curcumin, ethyl acetate hoặc 70% cao chiết từ thân rễ nghệ ở các nồng độ tương ứng với curcumin ở các nồng độ 2,5,5 và 10 µg / ml (/1,4,3) đơn độc hoặc kết hợp với ethanol 100 mm trong 24 giờ.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu nối chủ vành không có hỗ trợ tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.4201)\n",
      "\n",
      "============================================================\n",
      "Epoch 16/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:26<00:00,  7.06it/s, loss=1.5259]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.3881\n",
      "Val Loss  : 1.4037\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả tạo hình vú bằng vạt da cuống liền hai bên ở bệnh nhân ung thư vú có sẹo vùng bụng dưới.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân nhập viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể chất của họ, và chăm sóc tổng quát đúng chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu và tiến cứu, huyết áp được đo hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: tế bào được điều trị bằng curcumin, ethyl acetate hoặc 70% cao chiết từ thân rễ nghệ vàng ở các nồng độ tương ứng với curcumin ở các nồng độ 2,5, 5 và 10 µg / ml (/2 0,3,4, p < 0,001), đơn độc hoặc kết hợp với ethanol 100 mm trong 24 giờ.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu nối chủ vành không sử dụng tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.4037)\n",
      "\n",
      "============================================================\n",
      "Epoch 17/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:25<00:00,  7.07it/s, loss=1.5475]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.3615\n",
      "Val Loss  : 1.3883\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả phẫu thuật tái tạo vú bằng vạt da nhánh xuyên động mạch ngực trong điều trị ung thư vú có sẹo mổ vùng bụng dưới.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: người bệnh nhập viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể chất, và chăm sóc chung đúng chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu và tiến cứu, huyết áp được đo hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: tế bào được điều trị bằng curcumin, ethyl acetate hoặc 70% cao chiết từ thân nghệ vàng ở các nồng độ tương ứng với curcumin ở 2,5, 5 và 10 µg / ml (/1,4,4,1,4) đơn độc hoặc kết hợp với ethanol 100 mm trong 24h.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu mạch vành không sử dụng tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.3883)\n",
      "\n",
      "============================================================\n",
      "Epoch 18/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:33<00:00,  7.03it/s, loss=1.2364]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.3376\n",
      "Val Loss  : 1.3658\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả tạo hình vú bằng vạt da nhánh xuyên động mạch vú trong điều trị ung thư vú có sẹo mổ vùng bụng dưới.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: người bệnh nhập viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể chất, và hoạt động chăm sóc tổng quát đúng chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu và tiến cứu, huyết áp được đo hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: tế bào được xử lý bằng curcumin, ethyl acetate hoặc 70% cao chiết ethanol từ thân rễ nghệ ở các nồng độ tương ứng với curcumin ở các nồng độ 2,5, 5 và 10 µg / ml (/1, -2, -7, -3) đơn độc hoặc phối hợp với ethanol 100 mm trong 24 giờ.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả các bệnh nhân được phẫu thuật bắc cầu chủ vành không sử dụng tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.3658)\n",
      "\n",
      "============================================================\n",
      "Epoch 19/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:31<00:00,  7.03it/s, loss=1.3408]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.3162\n",
      "Val Loss  : 1.3590\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả tạo hình vú bằng vạt cuống mạch xuyên cuống cùng bên ở bệnh nhân ung thư vú có sẹo mổ vùng bụng dưới.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: người bệnh vào viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể chất, và hoạt động chăm sóc chung đúng chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: đây là nghiên cứu hồi cứu và tiến cứu, đo huyết áp hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: tế bào được xử lý curcumin, ethyl acetate hoặc 70% chiết xuất từ cao chiết cồn 96% từ thân rễ nghệ vàng tương ứng với curcumin ở 2,5,5 và 10 µg / ml (/10 µg / ml (/1,4,4,1) đơn độc hoặc kết hợp với ethanol 100 mm trong 24h.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu nối chủ vành không sử dụng tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.3590)\n",
      "\n",
      "============================================================\n",
      "Epoch 20/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9509 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 9509/9509 [22:34<00:00,  7.02it/s, loss=1.2705]\n",
      "Evaluating:   0%|          | 0/504 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 504/504 [00:23<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 1.2972\n",
      "Val Loss  : 1.3534\n",
      "\n",
      "Sample Translations:\n",
      "EN: Objectives: To assessement outcome of breast reconstruction with the ispilateral pedicled TRAM flap in breast cancer patient having the low abdominal scars.\n",
      "VI: mục tiêu: đánh giá kết quả tái tạo vú bằng vạt nhánh xuyên động mạch ngực trong điều trị ung thư vú có sẹo mổ vùng bụng dưới.\n",
      "---\n",
      "EN: Conclusion: Patients admitted to the hospital in a state of high decompensated cirrhosis, nutritional care helps to improve their physical condition, and correct general care activities account for 89.93%.\n",
      "VI: kết luận: bệnh nhân nhập viện trong tình trạng xơ gan mất bù, chăm sóc dinh dưỡng giúp cải thiện tình trạng thể chất của họ, và các hoạt động chăm sóc chung đúng chiếm 89,93%.\n",
      "---\n",
      "EN: This was a retrospective and prospective study, blood pressure was measured daily before and early post - transplantation, and 10 days continuously.\n",
      "VI: nghiên cứu hồi cứu và tiến cứu, huyết áp được đo hàng ngày trước và sau ghép, và 10 ngày liên tục.\n",
      "---\n",
      "EN: Cells were treated to curcumin, ethyl acetate or 70% ethanolic extracts from turmeric rhizomes at concentrations corresponding to that of curcumin at 2.5, 5 and 10 µg / ml (NĐ1, NĐ2, NĐ3) alone or combined with 100 mM ethanol for 24h.\n",
      "VI: tế bào được xử lý curcumin, ethyl acetat hoặc 70% chiết xuất từ thân rễ nghệ với nồng độ tương ứng với curcumin ở 2,5,5 và 10 µg / ml (/sxk) (/sxkm, cxcm, cxcm, cxcm, c-e) đơn độc hoặc kết hợp với ethanol 100 mm trong 24h.\n",
      "---\n",
      "EN: All patients underwent CABG without using cardio-pulmonary bypass support.\n",
      "VI: tất cả bệnh nhân được phẫu thuật bắc cầu mạch vành không sử dụng tuần hoàn ngoài cơ thể.\n",
      "---\n",
      "✓ Saved best model (val_loss=1.3534)\n",
      "\n",
      "Training complete!\n",
      "\n",
      "Calculating BLEU on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLEU Score: 45.69\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FULL TRAINING SCRIPT (CLEAN + FIXED BLEU + FIXED DECODE)\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import sacrebleu\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Greedy Decode\n",
    "# ============================================================================\n",
    "def greedy_decode(model, src, tokenizer, max_len=100):\n",
    "    model.eval()\n",
    "    device = src.device\n",
    "\n",
    "    sos_id = tokenizer.bos_token_id\n",
    "    eos_id = tokenizer.eos_token_id\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "\n",
    "    # Create source mask\n",
    "    src_mask = model.make_src_mask(src)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Encode source sequence\n",
    "        memory = model.encode(src, src_mask)\n",
    "\n",
    "        # Start decoder input with <sos>\n",
    "        ys = torch.full(\n",
    "            (src.size(0), 1),\n",
    "            fill_value=sos_id,\n",
    "            dtype=torch.long,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        for _ in range(max_len):\n",
    "\n",
    "            # Create target/causal mask\n",
    "            tgt_mask = model.make_tgt_mask(ys)\n",
    "\n",
    "            # Decode\n",
    "            out = model.decode(ys, memory, src_mask, tgt_mask)\n",
    "\n",
    "            # Project to vocab & pick top token\n",
    "            logits = model.output_projection(out[:, -1])  # last step\n",
    "            next_word = torch.argmax(logits, dim=-1).unsqueeze(1)\n",
    "\n",
    "            # Append\n",
    "            ys = torch.cat([ys, next_word], dim=1)\n",
    "\n",
    "            # Stop if all sentences predicted EOS\n",
    "            if (next_word == eos_id).all():\n",
    "                break\n",
    "\n",
    "    return ys\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Proper BLEU Computation (Correct sacrebleu Format)\n",
    "# ============================================================================\n",
    "\n",
    "def compute_bleu(model, dataloader, tokenizer, device):\n",
    "    model.eval()\n",
    "\n",
    "    hypotheses = []\n",
    "    reference_stream = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "\n",
    "        # match collate_fn keys\n",
    "        src = batch[\"src\"].to(device)\n",
    "        tgt = batch[\"tgt\"]\n",
    "\n",
    "        # Greedy decode predictions\n",
    "        pred_ids = greedy_decode(model, src, tokenizer, max_len=100)\n",
    "\n",
    "        for i in range(src.size(0)):\n",
    "\n",
    "            # ----- Decode Prediction -----\n",
    "            pred = pred_ids[i].tolist()\n",
    "            if tokenizer.eos_token_id in pred:\n",
    "                pred = pred[:pred.index(tokenizer.eos_token_id)]\n",
    "            pred_text = tokenizer.decode(pred, skip_special_tokens=True)\n",
    "\n",
    "            # ----- Decode Reference -----\n",
    "            ref = tgt[i].tolist()\n",
    "            if tokenizer.eos_token_id in ref:\n",
    "                ref = ref[:ref.index(tokenizer.eos_token_id)]\n",
    "            ref_text = tokenizer.decode(ref, skip_special_tokens=True)\n",
    "\n",
    "            hypotheses.append(pred_text)\n",
    "            reference_stream.append(ref_text)\n",
    "\n",
    "    bleu = sacrebleu.corpus_bleu(hypotheses, [reference_stream])\n",
    "    return bleu.score\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "def train():\n",
    "    import torch.optim as optim\n",
    "\n",
    "    # Hyperparameters\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_EPOCHS = 20\n",
    "    LEARNING_RATE = 1e-4\n",
    "    D_MODEL = 384\n",
    "    NUM_HEADS = 6\n",
    "    NUM_LAYERS = 5\n",
    "    D_FF = 1536\n",
    "    DROPOUT = 0.15\n",
    "    MAX_LEN = 256\n",
    "\n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = PreTrainedTokenizerFast.from_pretrained(\"medical_envi_tokenizer\")\n",
    "\n",
    "    # Datasets\n",
    "    train_dataset = TranslationDataset(dataset[\"train\"], tokenizer, max_len=MAX_LEN)\n",
    "    val_dataset = TranslationDataset(dataset[\"validation\"], tokenizer, max_len=MAX_LEN)\n",
    "    test_dataset = TranslationDataset(dataset[\"test\"], tokenizer, max_len=MAX_LEN)\n",
    "    \n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=lambda b: collate_fn(b, tokenizer.pad_token_id),\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda b: collate_fn(b, tokenizer.pad_token_id),\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda b: collate_fn(b, tokenizer.pad_token_id),\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model = TransformerTranslator(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        num_encoder_layers=NUM_LAYERS,\n",
    "        num_decoder_layers=NUM_LAYERS,\n",
    "        d_ff=D_FF,\n",
    "        max_len=MAX_LEN,\n",
    "        dropout=DROPOUT,\n",
    "        pad_idx=tokenizer.pad_token_id\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"\\nModel Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    # Loss + Optimizer\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        betas=(0.9, 0.98),\n",
    "        eps=1e-9\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"\\nTrain Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss  : {val_loss:.4f}\")\n",
    "        \n",
    "        print(\"\\nSample Translations:\")\n",
    "        for s in medical_examples:\n",
    "            translation = translate_sentence(model, tokenizer, s, device)\n",
    "            print(f\"EN: {s}\")\n",
    "            print(f\"VI: {translation}\")\n",
    "            print(\"---\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"val_loss\": val_loss,\n",
    "            }, \"best_medical_translator.pt\")\n",
    "\n",
    "            print(f\"✓ Saved best model (val_loss={val_loss:.4f})\")\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "\n",
    "    # ============================================================================\n",
    "    # BLEU Evaluation\n",
    "    # ============================================================================\n",
    "\n",
    "    print(\"\\nCalculating BLEU on validation set...\")\n",
    "    bleu_score = compute_bleu(model, test_loader, tokenizer, device)\n",
    "    print(f\"\\nBLEU Score: {bleu_score:.2f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "# Run training\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc7439",
   "metadata": {
    "papermill": {
     "duration": 15.497279,
     "end_time": "2025-12-12T23:07:42.735889",
     "exception": false,
     "start_time": "2025-12-12T23:07:27.238610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 285362068,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27760.223903,
   "end_time": "2025-12-12T23:08:01.627349",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-12T15:25:21.403446",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1557743001974f1fb4c21ba3b0862b20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "233f1225fa574b43a2acaa2f88c2d59e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2b9b68397bee428795241bae5df1ae0a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c32838a20bb45faaaaf327fd0da3a77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d9d27fc65434b3681ed5c8e8e5c6656": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8849295d4fc9444ba3e1ffe1888ab737",
        "IPY_MODEL_722fd1f63e6b4f9e92874f4f5d1c1c56",
        "IPY_MODEL_924958110f904b0c92e856bddd0cb1ef"
       ],
       "layout": "IPY_MODEL_994fbe28b1624ece9b97f216f935f196",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2e4a47e4c98b41ad8edf3f49042a1457": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c9b25808fae7412da9e8e0039aab308e",
       "placeholder": "​",
       "style": "IPY_MODEL_d75479ceba8841d2a9cd2a09d8f29832",
       "tabbable": null,
       "tooltip": null,
       "value": " 322045/0 [00:01&lt;00:00, 224079.71 examples/s]"
      }
     },
     "30605e7293c649899574516780038507": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d2e752d6028f41389ff6df2ba667fdae",
       "placeholder": "​",
       "style": "IPY_MODEL_3b0bba2e478e4ac3b67eb1084bb5f104",
       "tabbable": null,
       "tooltip": null,
       "value": "Generating test split: "
      }
     },
     "3b0bba2e478e4ac3b67eb1084bb5f104": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4336abc315fe4cbfae43a8a691c38a5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "449e17242ad3435681e6afe280020d95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "45dff8efed164e7a97413571083f87e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "4624ba95d8b94091a7e0c228d7bb90ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "55c761496eed4f5d80c14b70ec35f096": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_30605e7293c649899574516780038507",
        "IPY_MODEL_b479bde3d93a4a90806bbdcdc29063da",
        "IPY_MODEL_b93b9154c9834e55afc6cde4c7c5da8b"
       ],
       "layout": "IPY_MODEL_df5b66b9c8514e03a8bc86a5202c3e1a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "56f678bd3de24afcb8b39c984d65c2f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8030ef94ff9748b4a0d703139019ea34",
        "IPY_MODEL_f37d0a49cfa4484b9d2d6b83587f588f",
        "IPY_MODEL_2e4a47e4c98b41ad8edf3f49042a1457"
       ],
       "layout": "IPY_MODEL_b44c02455f2549878d45f26e1a403f1c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5bda53c81c3a4344ae0927a82055113b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5dcec8bcdf2544bd822c3d49796815c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "66113944efed412caa2977af8bd96e04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "675c8fabf424484eaf41cfe4599dc5a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6ff0fed5996943ac95804872ed2bc530": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "722fd1f63e6b4f9e92874f4f5d1c1c56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d959e50754b9423184c3a8410720e8b8",
       "max": 305942.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4624ba95d8b94091a7e0c228d7bb90ee",
       "tabbable": null,
       "tooltip": null,
       "value": 305942.0
      }
     },
     "7405c8dde518435896e83b27d585ee0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8114cd16d67047c5ba71b09a2db675ff",
       "placeholder": "​",
       "style": "IPY_MODEL_bfa56d037062402b9f79c75ac746ecaa",
       "tabbable": null,
       "tooltip": null,
       "value": " 2/2 [00:00&lt;00:00, 307.37it/s]"
      }
     },
     "78376344e93d4167be0f019a25de86d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8030ef94ff9748b4a0d703139019ea34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f42e277d40464169ab9875614bb68423",
       "placeholder": "​",
       "style": "IPY_MODEL_6ff0fed5996943ac95804872ed2bc530",
       "tabbable": null,
       "tooltip": null,
       "value": "Generating train split: "
      }
     },
     "8114cd16d67047c5ba71b09a2db675ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8849295d4fc9444ba3e1ffe1888ab737": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5bda53c81c3a4344ae0927a82055113b",
       "placeholder": "​",
       "style": "IPY_MODEL_f33d9dd985e4469d8d41e1b39d6f1bfa",
       "tabbable": null,
       "tooltip": null,
       "value": "Filter: 100%"
      }
     },
     "924958110f904b0c92e856bddd0cb1ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1557743001974f1fb4c21ba3b0862b20",
       "placeholder": "​",
       "style": "IPY_MODEL_5dcec8bcdf2544bd822c3d49796815c3",
       "tabbable": null,
       "tooltip": null,
       "value": " 305942/305942 [00:03&lt;00:00, 97907.13 examples/s]"
      }
     },
     "962f03a8b6a64140bafe6c1aa49ddfd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "994fbe28b1624ece9b97f216f935f196": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c4bf91658ce42e1bbffa86667149588": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2b9b68397bee428795241bae5df1ae0a",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4336abc315fe4cbfae43a8a691c38a5d",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "b44c02455f2549878d45f26e1a403f1c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b479bde3d93a4a90806bbdcdc29063da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_962f03a8b6a64140bafe6c1aa49ddfd5",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d0a94b71a172495ea175e09e44d40f33",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "b93b9154c9834e55afc6cde4c7c5da8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_66113944efed412caa2977af8bd96e04",
       "placeholder": "​",
       "style": "IPY_MODEL_675c8fabf424484eaf41cfe4599dc5a7",
       "tabbable": null,
       "tooltip": null,
       "value": " 2793/0 [00:00&lt;00:00, 169307.02 examples/s]"
      }
     },
     "bfa56d037062402b9f79c75ac746ecaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c9b25808fae7412da9e8e0039aab308e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0a94b71a172495ea175e09e44d40f33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d2e752d6028f41389ff6df2ba667fdae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d75479ceba8841d2a9cd2a09d8f29832": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d959e50754b9423184c3a8410720e8b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9a1bcd0938e4d60865b0be7a7c198c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2c32838a20bb45faaaaf327fd0da3a77",
       "placeholder": "​",
       "style": "IPY_MODEL_449e17242ad3435681e6afe280020d95",
       "tabbable": null,
       "tooltip": null,
       "value": "Computing checksums: 100%"
      }
     },
     "df5b66b9c8514e03a8bc86a5202c3e1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef05816ef33543dc8a17d8c6bb0b37e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d9a1bcd0938e4d60865b0be7a7c198c3",
        "IPY_MODEL_9c4bf91658ce42e1bbffa86667149588",
        "IPY_MODEL_7405c8dde518435896e83b27d585ee0f"
       ],
       "layout": "IPY_MODEL_78376344e93d4167be0f019a25de86d3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f33d9dd985e4469d8d41e1b39d6f1bfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f37d0a49cfa4484b9d2d6b83587f588f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_45dff8efed164e7a97413571083f87e9",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_233f1225fa574b43a2acaa2f88c2d59e",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "f42e277d40464169ab9875614bb68423": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
